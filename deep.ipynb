{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykite as pk\n",
    "from learning_utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_attack=pk.coefficients.shape[0]\n",
    "n_bank=pk.bank_angles.shape[0]\n",
    "n_beta=pk.n_beta\n",
    "gamma=1\n",
    "eps0=0.01\n",
    "episode_duration=180\n",
    "learning_step=0.2\n",
    "horizon=int(episode_duration/learning_step)\n",
    "integration_step=0.001\n",
    "integration_steps_per_learning_step=int(learning_step/integration_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(3, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 9)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon  0.01   0 Simulation failed at learning step:  623  reward  -7762.617027769986 loss  tensor(8264.2852, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   1 Simulation failed at learning step:  524  reward  -8342.648291436022 loss  tensor(9811.0889, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   2 Simulation failed at learning step:  30  reward  -299026.52596895624 loss  tensor(299999.9062, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   3 Simulation failed at learning step:  89  reward  -299155.1881457503 loss  tensor(300000.1562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   4 Simulation failed at learning step:  630  reward  -7635.096264236248 loss  tensor(8177.8789, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   5 Simulation failed at learning step:  190  reward  -298420.852733405 loss  tensor(300000.9688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   6 Simulation failed at learning step:  66  reward  -299575.3966437006 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   7 Simulation failed at learning step:  84  reward  -299310.50526297407 loss  tensor(299999.1562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   8 Simulation failed at learning step:  314  reward  -22646.44601239993 loss  tensor(20300.3672, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   9 Simulation failed at learning step:  244  reward  -52361.01807479169 loss  tensor(51271.8086, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   10 Simulation failed at learning step:  124  reward  -299665.0490716573 loss  tensor(300000.8438, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   11 Simulation failed at learning step:  304  reward  -24308.02326471247 loss  tensor(21805.2148, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   12 Simulation failed at learning step:  33  reward  -298972.03840538143 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   13 Simulation failed at learning step:  93  reward  -299346.523077612 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   14 Simulation failed at learning step:  94  reward  -299354.9906679423 loss  tensor(299999.2812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   15 Simulation failed at learning step:  173  reward  -299832.77378901484 loss  tensor(299998.3125, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   16 Simulation failed at learning step:  105  reward  -299427.1026754262 loss  tensor(299998.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   17 Simulation failed at learning step:  128  reward  -299317.51987368637 loss  tensor(300001.4062, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   18 Simulation failed at learning step:  237  reward  -67864.10436514366 loss  tensor(67547.7422, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   19 Simulation failed at learning step:  208  reward  -300414.13818695006 loss  tensor(300001.2188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   20 Simulation failed at learning step:  85  reward  -299864.99581821274 loss  tensor(299999.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   21 Simulation failed at learning step:  109  reward  -299443.0700201804 loss  tensor(299999.2812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   22 Simulation failed at learning step:  98  reward  -299346.55586329923 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   23 Simulation failed at learning step:  50  reward  -299341.63296471135 loss  tensor(300000.9062, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   24 Simulation failed at learning step:  119  reward  -299272.0296310979 loss  tensor(299997.7812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   25 Simulation failed at learning step:  189  reward  -300068.0300071868 loss  tensor(299999.0312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   26 Simulation failed at learning step:  126  reward  -299572.67413544876 loss  tensor(300001.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   27 Simulation failed at learning step:  96  reward  -299158.02709155576 loss  tensor(300002.3750, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   28 Simulation failed at learning step:  96  reward  -299370.73572973843 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   29 Simulation failed at learning step:  94  reward  -299390.7332367353 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   30 Simulation failed at learning step:  92  reward  -299358.0282894398 loss  tensor(299999.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   31 Simulation failed at learning step:  2  reward  -299942.62696485315 loss  tensor(300000.0312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   32 Simulation failed at learning step:  95  reward  -299334.2112323704 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   33 Simulation failed at learning step:  95  reward  -299363.5916962804 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   34 Simulation failed at learning step:  95  reward  -299356.22109685675 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   35 Simulation failed at learning step:  73  reward  -299324.7406728547 loss  tensor(300001.0312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   36 Simulation failed at learning step:  222  reward  -299862.4037394106 loss  tensor(300001.8125, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   37 Simulation failed at learning step:  193  reward  -303750.72817806667 loss  tensor(300001.0625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   38 Simulation failed at learning step:  305  reward  -25281.713210412363 loss  tensor(21644.8848, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   39 Simulation failed at learning step:  47  reward  -299413.77909787686 loss  tensor(299997.8750, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   40 Simulation failed at learning step:  172  reward  -300308.0008104437 loss  tensor(300000.9375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   41 Simulation failed at learning step:  77  reward  -299309.006348254 loss  tensor(300002.7812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   42 Simulation failed at learning step:  98  reward  -299328.7857609451 loss  tensor(300000.8125, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   43 Simulation failed at learning step:  54  reward  -299323.4080958432 loss  tensor(300000.8438, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   44 Simulation failed at learning step:  328  reward  -21457.61984899027 loss  tensor(18600.8867, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   45 Simulation failed at learning step:  148  reward  -300650.2153259264 loss  tensor(300001.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   46 Simulation failed at learning step:  111  reward  -299655.97015098244 loss  tensor(300000.2812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   47 Simulation failed at learning step:  86  reward  -299628.9494267085 loss  tensor(299999.0938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   48 Simulation failed at learning step:  51  reward  -299309.82619156153 loss  tensor(299997.7500, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   49 Simulation failed at learning step:  103  reward  -299261.7397363938 loss  tensor(300000.7500, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   50 Simulation failed at learning step:  55  reward  -299488.23473559634 loss  tensor(299999.0312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   51 Simulation failed at learning step:  302  reward  -24096.598923603247 loss  tensor(22142.8340, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   52 Simulation failed at learning step:  260  reward  -37907.99067056909 loss  tensor(35541.3633, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   53 Simulation failed at learning step:  67  reward  -299586.803521748 loss  tensor(300001.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   54 Simulation failed at learning step:  90  reward  -299392.13170055364 loss  tensor(300003.1250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   55 Simulation failed at learning step:  63  reward  -299479.34244763677 loss  tensor(300000.8125, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   56 Simulation failed at learning step:  92  reward  -299199.33006438613 loss  tensor(300000.8750, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   57 Simulation failed at learning step:  312  reward  -23062.346145850202 loss  tensor(20575.6504, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   58 Simulation failed at learning step:  42  reward  -299128.945603807 loss  tensor(300003., grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   59 Simulation failed at learning step:  305  reward  -24628.999652169714 loss  tensor(21642.0234, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   60 Simulation failed at learning step:  230  reward  -115797.70621498747 loss  tensor(114222.5078, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.01   61 Simulation failed at learning step:  156  reward  -300475.27575903555 loss  tensor(300002.2500, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.0018269667656457247   62 Simulation failed at learning step:  178  reward  -300203.11049424787 loss  tensor(300002.2812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.00031339854838979944   63 Simulation failed at learning step:  303  reward  -24999.007554227614 loss  tensor(21978.9375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.00021490281545395005   64 Simulation failed at learning step:  280  reward  -30372.473180175773 loss  tensor(27097.3574, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.0002075427623326513   65 Simulation failed at learning step:  35  reward  -299069.49645352864 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.00016490525322449418   66 Simulation failed at learning step:  297  reward  -26049.84714337025 loss  tensor(23060.4746, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.00014087231548674578   67 Simulation failed at learning step:  280  reward  -30372.473180175773 loss  tensor(27097.3691, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.00012386801986336935   68 Simulation failed at learning step:  290  reward  -27669.382940696727 loss  tensor(24513.1914, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.0001117979385555701   69 Simulation failed at learning step:  280  reward  -30372.473180175773 loss  tensor(27097.3555, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  0.00010227962790136449   70 Simulation failed at learning step:  285  reward  -29058.991747312408 loss  tensor(25726.6738, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.465474890551249e-05   71 Simulation failed at learning step:  285  reward  -29058.991747312408 loss  tensor(25726.9824, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  8.837870532532398e-05   72 Simulation failed at learning step:  285  reward  -29058.991747312408 loss  tensor(25727.2930, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  8.310224611767726e-05   73 Simulation failed at learning step:  285  reward  -29058.991747312408 loss  tensor(25727.6367, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.853148623358958e-05   74 Simulation failed at learning step:  289  reward  -28004.73442189095 loss  tensor(24751.0508, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.465150032382497e-05   75 Simulation failed at learning step:  283  reward  -29625.424814438837 loss  tensor(26256.7891, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.12213652373281e-05   76 Simulation failed at learning step:  285  reward  -29058.991747312408 loss  tensor(25728.6074, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.820175858935452e-05   77 Simulation failed at learning step:  283  reward  -29625.424814438837 loss  tensor(26257.4570, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.550106298384562e-05   78 Simulation failed at learning step:  283  reward  -29625.424814438837 loss  tensor(26257.7832, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.306792885001369e-05   79 Simulation failed at learning step:  283  reward  -29625.424814438837 loss  tensor(26258.1270, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.0861788305117417e-05   80 Simulation failed at learning step:  283  reward  -29625.424814438837 loss  tensor(26258.4551, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8877232169746473e-05   81 Simulation failed at learning step:  279  reward  -30670.196599483716 loss  tensor(27408.6094, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.705635997688345e-05   82 Simulation failed at learning step:  279  reward  -30670.196599483716 loss  tensor(27408.9551, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.537830726302645e-05   83 Simulation failed at learning step:  279  reward  -30670.196599483716 loss  tensor(27409.2930, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.387382817734739e-05   84 Simulation failed at learning step:  270  reward  -33767.92019164033 loss  tensor(30564.0215, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.242878013100181e-05   85 Simulation failed at learning step:  279  reward  -30670.196599483716 loss  tensor(27409.9844, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.0953086908408955e-05   86 Simulation failed at learning step:  307  reward  -24836.805430274268 loss  tensor(21336.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.960036444944149e-05   87 Simulation failed at learning step:  303  reward  -25455.161406340823 loss  tensor(21986.5703, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.827533795209501e-05   88 Simulation failed at learning step:  319  reward  -22991.77780206918 loss  tensor(19659.8809, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.704068495387564e-05   89 Simulation failed at learning step:  319  reward  -22991.77780206918 loss  tensor(19660.2324, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.594270644461888e-05   90 Simulation failed at learning step:  303  reward  -25507.43823279969 loss  tensor(21987.6992, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.491051319482223e-05   91 Simulation failed at learning step:  303  reward  -25507.43823279969 loss  tensor(21988.0645, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.395969697930099e-05   92 Simulation failed at learning step:  296  reward  -26236.114363711 loss  tensor(23247.8555, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.323838524094526e-05   93 Simulation failed at learning step:  236  reward  -74289.18065854993 loss  tensor(71168.9922, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.253639163404116e-05   94 Simulation failed at learning step:  240  reward  -62341.304670609265 loss  tensor(59084.3242, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.172530168459461e-05   95 Simulation failed at learning step:  291  reward  -27467.584688288014 loss  tensor(24306.1426, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.0956761499886645e-05   96 Simulation failed at learning step:  290  reward  -27504.668740231908 loss  tensor(24512.3555, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  4.0291290811198776e-05   97 Simulation failed at learning step:  263  reward  -36957.43572234624 loss  tensor(33844.7852, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.958080167723789e-05   98 Simulation failed at learning step:  294  reward  -26665.789830620943 loss  tensor(23649.5234, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.927124048109275e-05   99 Simulation failed at learning step:  132  reward  -300546.5302782557 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.9156523956657035e-05   100 Simulation failed at learning step:  49  reward  -299192.06929815764 loss  tensor(300000.7812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.869315008944871e-05   101 Simulation failed at learning step:  205  reward  -300449.2985007179 loss  tensor(300001.3438, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.855433570624109e-05   102 Simulation failed at learning step:  62  reward  -299327.57419240964 loss  tensor(300000.8125, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.81137966484669e-05   103 Simulation failed at learning step:  203  reward  -300434.23369810526 loss  tensor(300001.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.801841492027193e-05   104 Simulation failed at learning step:  44  reward  -299180.1648119311 loss  tensor(300000.8438, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.795307666887631e-05   105 Simulation failed at learning step:  30  reward  -299205.0030217083 loss  tensor(300000.8750, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.7888037002268105e-05   106 Simulation failed at learning step:  30  reward  -299205.0030217083 loss  tensor(300000.9375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.782329370947814e-05   107 Simulation failed at learning step:  30  reward  -299205.0030217083 loss  tensor(300001., grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.775884460214157e-05   108 Simulation failed at learning step:  30  reward  -299205.0030217083 loss  tensor(300001.0312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.7705015769185625e-05   109 Simulation failed at learning step:  25  reward  -298975.6917825853 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  3.765344981428396e-05   110 Simulation failed at learning step:  24  reward  -298985.03475222783 loss  tensor(300000.8438, grad_fn=<SmoothL1LossBackward>)\n",
      "111 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  3.5866890035763005e-05   112 Simulation failed at learning step:  25  reward  -298975.6917825853 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "113 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  3.4289849243591055e-05   114 Simulation failed at learning step:  25  reward  -298975.6917825853 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "115 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  3.288225055254398e-05   116 Simulation failed at learning step:  27  reward  -299070.1504390895 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "117 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  3.161501371128847e-05   118 Simulation failed at learning step:  30  reward  -299205.0030217083 loss  tensor(300000.9062, grad_fn=<SmoothL1LossBackward>)\n",
      "119 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  3.04701650609545e-05   120 Simulation failed at learning step:  30  reward  -299205.0030217083 loss  tensor(300000.8438, grad_fn=<SmoothL1LossBackward>)\n",
      "121 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  2.9428521251334576e-05   122 Simulation failed at learning step:  31  reward  -299208.0708396278 loss  tensor(300000.8125, grad_fn=<SmoothL1LossBackward>)\n",
      "123 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  2.847672561000231e-05   124 Simulation failed at learning step:  31  reward  -299208.0708396278 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "125 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  2.7603727209829504e-05   126 Simulation failed at learning step:  30  reward  -299205.0030217083 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "127 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  2.6797801919124442e-05   128 Simulation failed at learning step:  31  reward  -299208.0708396278 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "129 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  2.6051715975522185e-05   130 Simulation failed at learning step:  31  reward  -299208.0708396278 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "131 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "132 Simulation ended at learning step:  899  reward  995.7234748013607\n",
      "epsilon  2.4733974037569275e-05   133 Simulation failed at learning step:  31  reward  -299208.0708396278 loss  tensor(300000.3750, grad_fn=<SmoothL1LossBackward>)\n",
      "134 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  2.4028045245294755e-05   135 Simulation failed at learning step:  192  reward  -300337.4230142758 loss  tensor(300001.3125, grad_fn=<SmoothL1LossBackward>)\n",
      "136 Simulation ended at learning step:  899  reward  701.4686003524383\n",
      "epsilon  2.3452275506744803e-05   137 Simulation failed at learning step:  56  reward  -299297.11410202656 loss  tensor(300000.1562, grad_fn=<SmoothL1LossBackward>)\n",
      "138 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "139 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  2.2359761424689173e-05   140 Simulation failed at learning step:  198  reward  -300387.6992004394 loss  tensor(300001.1562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.232495411914625e-05   141 Simulation failed at learning step:  67  reward  -299308.4195378682 loss  tensor(300000.2188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.2221393048750278e-05   142 Simulation failed at learning step:  203  reward  -300434.23369810526 loss  tensor(300001.2812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.213406709500035e-05   143 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.2047650320508867e-05   144 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.1962127442830978e-05   145 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.187748353292239e-05   146 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.1793704004763668e-05   147 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.1761194392212373e-05   148 Simulation failed at learning step:  67  reward  -299312.7964964165 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "149 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  2.1251315831265448e-05   150 Simulation failed at learning step:  202  reward  -300421.8852332631 loss  tensor(300001.3750, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.1173760469035924e-05   151 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.109695530073756e-05   152 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.1068891501821718e-05   153 Simulation failed at learning step:  63  reward  -299289.85275731154 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "154 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  2.0600366604236625e-05   155 Simulation failed at learning step:  202  reward  -300421.8852332631 loss  tensor(300001.3438, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.0528968030842223e-05   156 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.0458225560190744e-05   157 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.0388129450893847e-05   158 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  2.036170836929584e-05   159 Simulation failed at learning step:  65  reward  -299299.2532721202 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "160 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "161 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  1.9602404416307845e-05   162 Simulation failed at learning step:  198  reward  -300387.6992004394 loss  tensor(300001.3750, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.9539838101183997e-05   163 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.9477801494378638e-05   164 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.9449454675953215e-05   165 Simulation failed at learning step:  79  reward  -299426.33707634115 loss  tensor(300000.4062, grad_fn=<SmoothL1LossBackward>)\n",
      "166 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "167 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  1.8774423863139205e-05   168 Simulation failed at learning step:  200  reward  -300404.24239172036 loss  tensor(300001.3438, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.8718642621684964e-05   169 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.866330115827992e-05   170 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.8608393866345536e-05   171 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.855391523778769e-05   172 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.8530874755134522e-05   173 Simulation failed at learning step:  73  reward  -299371.61210847576 loss  tensor(300000.4062, grad_fn=<SmoothL1LossBackward>)\n",
      "174 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "175 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "176 Simulation ended at learning step:  899  reward  930.6614646000543\n",
      "epsilon  1.7682698591183536e-05   177 Simulation failed at learning step:  204  reward  -300437.1441564428 loss  tensor(300001.3125, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.7635135501453167e-05   178 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.7587912051069084e-05   179 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.754102431642306e-05   180 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.7494468436389222e-05   181 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.7448240611058228e-05   182 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.7402337100502552e-05   183 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.7356754223571945e-05   184 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.7311488356718204e-05   185 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.7266535932848448e-05   186 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "187 Simulation ended at learning step:  899  reward  986.0442805843924\n",
      "epsilon  1.6995801606657855e-05   188 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.695299759256058e-05   189 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "190 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  1.669501384592043e-05   191 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.6654196234450544e-05   192 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "193 Simulation ended at learning step:  899  reward  986.0442805843924\n",
      "epsilon  1.6408015140018684e-05   194 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.636881507066134e-05   195 Simulation failed at learning step:  174  reward  -300283.6729362637 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "196 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  1.6133592021419375e-05   197 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.6096112685190765e-05   198 Simulation failed at learning step:  174  reward  -300283.6729362637 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "199 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  1.5871076508806107e-05   200 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.5835198445240455e-05   201 Simulation failed at learning step:  174  reward  -300283.6729362637 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "202 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  1.5619651134409192e-05   203 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "204 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  1.5411754415397075e-05   205 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.5378574137649696e-05   206 Simulation failed at learning step:  174  reward  -300283.6729362637 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "207 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "epsilon  1.5179033977547646e-05   208 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.5163535241812801e-05   209 Simulation failed at learning step:  84  reward  -299241.80723995133 loss  tensor(300000.2188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.5123435228271002e-05   210 Simulation failed at learning step:  220  reward  -300550.274319629 loss  tensor(300006.9062, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.5092061529894744e-05   211 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.506086079359788e-05   212 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.502983147520803e-05   213 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4992785083931001e-05   214 Simulation failed at learning step:  208  reward  -300465.5584024631 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4962127735100993e-05   215 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4931636987503666e-05   216 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4901311374906658e-05   217 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4871149448884534e-05   218 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4840977832836735e-05   219 Simulation failed at learning step:  174  reward  -299986.21115425316 loss  tensor(300001.8125, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4811139924871021e-05   220 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4781461454339158e-05   221 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4751771838047294e-05   222 Simulation failed at learning step:  174  reward  -300283.6729362637 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "223 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.4567253227805744e-05   224 Simulation failed at learning step:  208  reward  -300465.5584024631 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4538858067051193e-05   225 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4510610026139813e-05   226 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "227 Simulation ended at learning step:  899  reward  951.6028669035064\n",
      "epsilon  1.4333946630244295e-05   228 Simulation failed at learning step:  208  reward  -300465.5584024631 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4306746190604945e-05   229 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4279682960269701e-05   230 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4251829709717503e-05   231 Simulation failed at learning step:  179  reward  -300162.2142520653 loss  tensor(300000.2188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4225042181925848e-05   232 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4198388500059875e-05   233 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.417186758074896e-05   234 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.4145478352726461e-05   235 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "236 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.3980310957983656e-05   237 Simulation failed at learning step:  208  reward  -300465.5584024631 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.395486081776829e-05   238 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3929533850892866e-05   239 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "240 Simulation ended at learning step:  899  reward  966.9869111324232\n",
      "epsilon  1.3771083552221632e-05   241 Simulation failed at learning step:  207  reward  -300453.64147407265 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3746635003542662e-05   242 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3722301859635183e-05   243 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "244 Simulation ended at learning step:  899  reward  966.9869111324232\n",
      "epsilon  1.3574067511613769e-05   245 Simulation failed at learning step:  177  reward  -300179.5045595992 loss  tensor(300000.2188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3550539285718869e-05   246 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3527119498547956e-05   247 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3503807340289627e-05   248 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3480602009482091e-05   249 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "250 Simulation ended at learning step:  899  reward  966.9869111324232\n",
      "epsilon  1.3335031011357424e-05   251 Simulation failed at learning step:  209  reward  -300479.1780820186 loss  tensor(300007.3438, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3312589994964382e-05   252 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3290249403948269e-05   253 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "254 Simulation ended at learning step:  899  reward  966.9869111324232\n",
      "epsilon  1.3150172894872338e-05   255 Simulation failed at learning step:  208  reward  -300465.5584024631 loss  tensor(300000.6562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3128550784497707e-05   256 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.3107023220528241e-05   257 Simulation failed at learning step:  173  reward  -300277.2203278536 loss  tensor(300000.6250, grad_fn=<SmoothL1LossBackward>)\n",
      "258 Simulation ended at learning step:  899  reward  966.9869111324232\n",
      "259 Simulation ended at learning step:  899  reward  966.9869111324232\n",
      "260 Simulation ended at learning step:  899  reward  730.0625658449345\n",
      "261 Simulation ended at learning step:  899  reward  982.8331536071823\n",
      "262 Simulation ended at learning step:  899  reward  966.9869111324232\n",
      "263 Simulation ended at learning step:  899  reward  967.0500347088204\n",
      "264 Simulation ended at learning step:  899  reward  981.3249963981812\n",
      "265 Simulation ended at learning step:  899  reward  964.9048038983483\n",
      "266 Simulation ended at learning step:  899  reward  981.3249963981812\n",
      "267 Simulation ended at learning step:  899  reward  965.4877448696518\n",
      "268 Simulation ended at learning step:  899  reward  981.3249963981812\n",
      "269 Simulation ended at learning step:  899  reward  981.3249963981812\n",
      "270 Simulation ended at learning step:  899  reward  981.3249963981812\n",
      "271 Simulation ended at learning step:  899  reward  981.3249963981812\n",
      "272 Simulation ended at learning step:  899  reward  918.0881373114545\n",
      "epsilon  1.1663425839138813e-05   273 Simulation failed at learning step:  175  reward  -300246.53860144404 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1636198344500795e-05   274 Simulation failed at learning step:  301  reward  -23298.152813161854 loss  tensor(22318.3906, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1621035553087978e-05   275 Simulation failed at learning step:  168  reward  -300293.2878081252 loss  tensor(300001.0625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1605479085858599e-05   276 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1589978027342526e-05   277 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1574532057552363e-05   278 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1559140859053727e-05   279 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1543804116939282e-05   280 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1528521518803085e-05   281 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1513292754715253e-05   282 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1498117517196958e-05   283 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.148299550119569e-05   284 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1467926404060857e-05   285 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1452909925519679e-05   286 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5938, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1437945767653355e-05   287 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1423033634873543e-05   288 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1408173233899117e-05   289 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1393364273733198e-05   290 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1378606465640479e-05   291 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1363899523124813e-05   292 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1349243161907064e-05   293 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1334637099903241e-05   294 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1320081057202883e-05   295 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1305574756047707e-05   296 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.12911179208105e-05   297 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1276710277974286e-05   298 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1262351556111708e-05   299 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1248041485864694e-05   300 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5625, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1233779799924317e-05   301 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1219566233010941e-05   302 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.120540052185456e-05   303 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1191282405175396e-05   304 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1177211623664713e-05   305 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1163187919965853e-05   306 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1149211038655506e-05   307 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1135280726225177e-05   308 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1121396731062896e-05   309 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1107558803435122e-05   310 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1093766695468857e-05   311 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1080020161133973e-05   312 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1066318956225742e-05   313 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1052662838347566e-05   314 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1039051566893907e-05   315 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.1025484903033408e-05   316 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.101196260969221e-05   317 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5312, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0998484451537468e-05   318 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0985050194961037e-05   319 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0971659608063364e-05   320 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0958312460637541e-05   321 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0945008524153559e-05   322 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.093174757174273e-05   323 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0918529378182284e-05   324 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0905353719880144e-05   325 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0892220374859869e-05   326 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0879129122745762e-05   327 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0866079744748159e-05   328 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0853072023648866e-05   329 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0840105743786767e-05   330 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0827180691043589e-05   331 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0814296652829829e-05   332 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.080145341807083e-05   333 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0788650777193026e-05   334 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0775888522110313e-05   335 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0763166446210598e-05   336 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0750484344342477e-05   337 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.5000, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0737842012802068e-05   338 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0725239249319988e-05   339 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0712675853048462e-05   340 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0700151624548592e-05   341 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0687666365777747e-05   342 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.06752198800771e-05   343 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  1.0662811972159288e-05   344 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "345 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.0587067581091152e-05   346 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "347 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.0512741229625347e-05   348 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "349 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.0439790276561479e-05   350 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "351 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.036817383582184e-05   352 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "353 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.0297852685186183e-05   354 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "355 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.0228789180739317e-05   356 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "357 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.0160947176614789e-05   358 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "359 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.009429194965243e-05   360 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "361 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  1.0028790128619053e-05   362 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "363 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.96440962767002e-06   364 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.954082705891452e-06   365 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.943784275229303e-06   366 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.933514208170934e-06   367 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "368 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.870743367795505e-06   369 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.860673068936684e-06   370 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.850630120611334e-06   371 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.840614402314172e-06   372 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "373 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.779388830444824e-06   374 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "375 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.719168646116818e-06   376 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "377 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.6599272938294e-06   378 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "379 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.60163917950901e-06   380 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "381 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.544279626475172e-06   382 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "383 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.487824833837409e-06   384 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "385 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.432251837166559e-06   386 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "387 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.377538471295366e-06   388 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "389 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.323663335113772e-06   390 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.315012450852339e-06   391 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.306382937948507e-06   392 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.297774710740504e-06   393 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.289187684041228e-06   394 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.280621773134913e-06   395 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.272076893773785e-06   396 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.263552962174773e-06   397 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  9.255049895016237e-06   398 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "399 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.203022330508068e-06   400 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "401 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.151767461085894e-06   402 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4688, grad_fn=<SmoothL1LossBackward>)\n",
      "403 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.101266810035325e-06   404 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "405 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  9.051502506813834e-06   406 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "407 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "408 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  8.961899440607302e-06   409 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.4375, grad_fn=<SmoothL1LossBackward>)\n",
      "410 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "411 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "412 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "413 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "414 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "415 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "416 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "417 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "418 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "419 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "420 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "421 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "422 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "423 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "424 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "425 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "426 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "427 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "428 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "429 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "430 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "431 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "432 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "433 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "434 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "435 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "436 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "437 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "438 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "439 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "440 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "441 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "442 Simulation ended at learning step:  899  reward  950.96363738042\n",
      "443 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "444 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "445 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "446 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "447 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "448 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "449 Simulation ended at learning step:  899  reward  982.4041786542435\n",
      "epsilon  7.654230004951764e-06   450 Simulation failed at learning step:  91  reward  -298918.1314760721 loss  tensor(300004.7812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.649116513544595e-06   451 Simulation failed at learning step:  173  reward  -300220.32270072855 loss  tensor(300000.2500, grad_fn=<SmoothL1LossBackward>)\n",
      "452 Simulation ended at learning step:  899  reward  970.2641423110339\n",
      "epsilon  7.6177543528493315e-06   453 Simulation failed at learning step:  173  reward  -300201.0312561658 loss  tensor(300000.2500, grad_fn=<SmoothL1LossBackward>)\n",
      "454 Simulation ended at learning step:  899  reward  953.7956064398162\n",
      "epsilon  7.586732766879695e-06   455 Simulation failed at learning step:  173  reward  -300201.0312561658 loss  tensor(300000.2812, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.581853285003811e-06   456 Simulation failed at learning step:  169  reward  -300051.21456201526 loss  tensor(300000.3125, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.576867648770699e-06   457 Simulation failed at learning step:  173  reward  -300200.56434421457 loss  tensor(300000.3125, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.571890745444707e-06   458 Simulation failed at learning step:  173  reward  -300201.1860855231 loss  tensor(299999.6562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.566922550195919e-06   459 Simulation failed at learning step:  173  reward  -300201.1860855231 loss  tensor(299999.6562, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.56196303829206e-06   460 Simulation failed at learning step:  173  reward  -300201.1860855231 loss  tensor(299999.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "461 Simulation ended at learning step:  899  reward  -1609.1059099794886\n",
      "epsilon  7.526924924884552e-06   462 Simulation failed at learning step:  337  reward  -18796.30592803419 loss  tensor(17692.1543, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.522034975144239e-06   463 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.51715348773417e-06   464 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.512280438882688e-06   465 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.507415804910499e-06   466 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.502559562230209e-06   467 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.6875, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.497711687345875e-06   468 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.492872156852545e-06   469 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.488040947435817e-06   470 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.483218035871385e-06   471 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.478403399024597e-06   472 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.4735970138500145e-06   473 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.468798857390968e-06   474 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.4640089067791305e-06   475 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.4592271392340724e-06   476 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.454453532062839e-06   477 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.449688062659517e-06   478 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.44493070850481e-06   479 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.440181447165612e-06   480 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.4354402562945925e-06   481 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.430707113629772e-06   482 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.425981996994109e-06   483 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.4212648842950865e-06   484 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.4165557535242975e-06   485 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.411854582757037e-06   486 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.407161350151903e-06   487 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.4024760339503825e-06   488 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.397798612476454e-06   489 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.393129064136191e-06   490 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.388467367417359e-06   491 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.383813500889029e-06   492 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.3791674432011764e-06   493 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.3745291730842985e-06   494 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.369898669349024e-06   495 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.365275910885726e-06   496 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.36066087666414e-06   497 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.356053545732988e-06   498 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.35145389721959e-06   499 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.346861910329496e-06   500 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.342277564346109e-06   501 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.33770083863031e-06   502 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.333131712620096e-06   503 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.328570165830201e-06   504 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.324016177851742e-06   505 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.319469728351844e-06   506 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.314930797073292e-06   507 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.310399363834157e-06   508 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.305875408527452e-06   509 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.301358911120767e-06   510 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.296849851655923e-06   511 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.292348210248614e-06   512 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.287853967088065e-06   513 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.283367102436681e-06   514 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.278887596629699e-06   515 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.2744154300748545e-06   516 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.269950583252029e-06   517 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.26549303671292e-06   518 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.261042771080698e-06   519 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.256599767049672e-06   520 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.252164005384962e-06   521 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.247735466922155e-06   522 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.243314132566992e-06   523 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.238899983295024e-06   524 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.234493000151299e-06   525 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.230093164250028e-06   526 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.225700456774271e-06   527 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.221314858975612e-06   528 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.216936352173841e-06   529 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.212564917756637e-06   530 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.208200537179255e-06   531 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.2038431919642115e-06   532 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.199492863700972e-06   533 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.195149534045644e-06   534 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.190813184720669e-06   535 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.186483797514512e-06   536 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.182161354281359e-06   537 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.177845836940821e-06   538 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.173537227477619e-06   539 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.1692355079413e-06   540 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.16494066044593e-06   541 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.160652667169798e-06   542 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.156371510355126e-06   543 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.152097172307773e-06   544 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.147829635396944e-06   545 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.1435688820549005e-06   546 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.139314894776678e-06   547 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.135067656119791e-06   548 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.130827148703953e-06   549 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.126593355210793e-06   550 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.122366258383576e-06   551 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.118145841026917e-06   552 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.113932086006509e-06   553 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.109724976248841e-06   554 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.1055244947409295e-06   555 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.1013306245300345e-06   556 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.097143348723394e-06   557 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.092962650487958e-06   558 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.0887885130501045e-06   559 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.0846209196953845e-06   560 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.0804598537682514e-06   561 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.076305298671794e-06   562 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.072157237867476e-06   563 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.0680156548748725e-06   564 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.0638805332714095e-06   565 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.059751856692105e-06   566 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.05562960882931e-06   567 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.051513773432453e-06   568 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.047404334307787e-06   569 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.043301275318132e-06   570 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.039204580382625e-06   571 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.035114233476466e-06   572 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.031030218630679e-06   573 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.026952519931846e-06   574 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.022881121521878e-06   575 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.018816007597757e-06   576 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.0147571624112984e-06   577 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.010704570268906e-06   578 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.006658215531331e-06   579 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  7.00261808261343e-06   580 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.998584155983929e-06   581 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.994556420165184e-06   582 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.990534859732944e-06   583 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.986519459316116e-06   584 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.982510203596534e-06   585 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.9785070773087235e-06   586 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.974510065239667e-06   587 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.970519152228585e-06   588 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.966534323166692e-06   589 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.962555562996981e-06   590 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.958582856713992e-06   591 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.954616189363587e-06   592 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.950655546042725e-06   593 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.946700911899241e-06   594 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.942752272131625e-06   595 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.9388096119887955e-06   596 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.934872916769892e-06   597 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.930942171824043e-06   598 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.927017362550158e-06   599 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.92309847439671e-06   600 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.9191854928615164e-06   601 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.915278403491532e-06   602 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.911377191882631e-06   603 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.9074818436794e-06   604 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.903592344574923e-06   605 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.899708680310578e-06   606 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.895830836675821e-06   607 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.891958799507987e-06   608 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.888092554692083e-06   609 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.8842320881605725e-06   610 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.880377385893191e-06   611 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.8765284339167245e-06   612 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.872685218304818e-06   613 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.868847725177775e-06   614 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.865015940702353e-06   615 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.8611898510915695e-06   616 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.857369442604499e-06   617 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.853554701546088e-06   618 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.849745614266943e-06   619 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.845942167163151e-06   620 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.842144346676077e-06   621 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.838352139292177e-06   622 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.834565531542801e-06   623 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.8307845100040105e-06   624 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.827009061296379e-06   625 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.823239172084812e-06   626 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.819474829078357e-06   627 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.815716019030013e-06   628 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.811962728736554e-06   629 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.808214945038331e-06   630 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.804472654819104e-06   631 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.800735845005845e-06   632 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.797004502568564e-06   633 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.79327861452013e-06   634 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.7895581679160845e-06   635 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.785843149854465e-06   636 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.78213354747563e-06   637 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.778429347962077e-06   638 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.77473053853827e-06   639 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.771037106470463e-06   640 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.767349039066525e-06   641 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.763666323675764e-06   642 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.759988947688759e-06   643 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.7563168985371876e-06   644 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.752650163693649e-06   645 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.7489887306715e-06   646 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.745332587024686e-06   647 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.741681720347568e-06   648 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.738036118274759e-06   649 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.734395768480954e-06   650 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.730760658680768e-06   651 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.727130776628567e-06   652 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.723506110118306e-06   653 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.719886646983368e-06   654 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.716272375096394e-06   655 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.712663282369129e-06   656 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.709059356752258e-06   657 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.705460586235246e-06   658 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.701866958846176e-06   659 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.698278462651596e-06   660 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.694695085756356e-06   661 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.691116816303455e-06   662 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.6875436424738815e-06   663 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.683975552486461e-06   664 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.6804125345977e-06   665 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.676854577101631e-06   666 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.6733016683296625e-06   667 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.669753796650421e-06   668 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.66621095046961e-06   669 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.662673118229844e-06   670 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.659140288410513e-06   671 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.655612449527624e-06   672 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.652089590133657e-06   673 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.648571698817414e-06   674 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.645058764203874e-06   675 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.641550774954045e-06   676 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.638047719764821e-06   677 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.634549587368835e-06   678 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.631056366534311e-06   679 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.627568046064931e-06   680 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.6240846147996805e-06   681 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.620606061612713e-06   682 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.617132375413207e-06   683 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.613663545145224e-06   684 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.6101995597875725e-06   685 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.606740408353662e-06   686 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.603286079891371e-06   687 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.599836563482904e-06   688 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.596391848244657e-06   689 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.5929519233270805e-06   690 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.58951677791454e-06   691 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.5860864012251876e-06   692 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.582660782510818e-06   693 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.579239911056746e-06   694 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.575823776181661e-06   695 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.572412367237505e-06   696 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.569005673609329e-06   697 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.565603684715173e-06   698 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.56220639000593e-06   699 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.558813778965213e-06   700 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.55542584110923e-06   701 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.552042565986654e-06   702 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.5486639431784925e-06   703 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.54528996229796e-06   704 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.541920612990356e-06   705 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.538555884932933e-06   706 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.53519576783477e-06   707 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.531840251436651e-06   708 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.52848932551094e-06   709 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.525142979861454e-06   710 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.521801204323343e-06   711 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.518463988762961e-06   712 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.515131323077753e-06   713 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.511803197196126e-06   714 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.508479601077329e-06   715 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.505160524711334e-06   716 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.501845958118716e-06   717 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.498535891350534e-06   718 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.495230314488208e-06   719 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.491929217643406e-06   720 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.488632590957924e-06   721 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.4853404246035665e-06   722 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.482052708782037e-06   723 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.478769433724811e-06   724 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.475490589693031e-06   725 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.472216166977385e-06   726 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.4689461558979945e-06   727 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.465680546804302e-06   728 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.462419330074953e-06   729 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.459162496117687e-06   730 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.455910035369225e-06   731 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.452661938295154e-06   732 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.4494181953898245e-06   733 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.446178797176227e-06   734 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.442943734205894e-06   735 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.43971299705878e-06   736 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.436486576343162e-06   737 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.433264462695523e-06   738 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.430046646780449e-06   739 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.426833119290517e-06   740 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.423623870946192e-06   741 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.420418892495716e-06   742 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.417218174715008e-06   743 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.41402170840755e-06   744 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.410829484404291e-06   745 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.407641493563533e-06   746 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.404457726770834e-06   747 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.401278174938904e-06   748 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.3981028290074935e-06   749 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.3949316799433006e-06   750 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.391764718739866e-06   751 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.3886019364174665e-06   752 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.385443324023019e-06   753 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.382288872629977e-06   754 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.379138573338231e-06   755 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.3759924172740104e-06   756 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.372850395589779e-06   757 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.36971249946414e-06   758 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.366578720101738e-06   759 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.363449048733156e-06   760 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.360323476614824e-06   761 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.3572019950289165e-06   762 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.35408459528326e-06   763 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.350971268711232e-06   764 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.347862006671671e-06   765 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.344756800548775e-06   766 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.3416556417520095e-06   767 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.338558521716012e-06   768 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.335465431900502e-06   769 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.332376363790179e-06   770 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.329291308894635e-06   771 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.326210258748264e-06   772 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.323133204910161e-06   773 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.320060138964036e-06   774 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.316991052518124e-06   775 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.313925937205088e-06   776 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.310864784681932e-06   777 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.307807586629911e-06   778 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.304754334754438e-06   779 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.301705020784998e-06   780 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.298659636475055e-06   781 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.295618173601967e-06   782 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.292580623966896e-06   783 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.2895469793947164e-06   784 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.286517231733938e-06   785 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.283491372856603e-06   786 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.280469394658216e-06   787 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.2774512890576425e-06   788 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.2744370479970355e-06   789 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.271426663441741e-06   790 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.268420127380216e-06   791 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.265417431823947e-06   792 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.262418568807357e-06   793 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.259423530387731e-06   794 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.256432308645125e-06   795 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.253444895682287e-06   796 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.250461283624569e-06   797 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.247481464619854e-06   798 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.244505430838462e-06   799 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.241533174473077e-06   800 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.238564687738658e-06   801 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.235599962872366e-06   802 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.232638992133477e-06   803 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.229681767803305e-06   804 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.22672828218512e-06   805 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.223778527604067e-06   806 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.220832496407091e-06   807 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.2178901809628534e-06   808 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.214951573661657e-06   809 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.212016666915364e-06   810 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.209085453157322e-06   811 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.206157924842281e-06   812 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.203234074446325e-06   813 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.200313894466783e-06   814 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.197397377422163e-06   815 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.19448451585207e-06   816 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.1915753023171305e-06   817 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.18866972939892e-06   818 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.185767789699884e-06   819 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.182869475843264e-06   820 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.179974780473025e-06   821 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.177083696253779e-06   822 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.174196215870712e-06   823 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.171312332029508e-06   824 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.168432037456281e-06   825 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.165555324897493e-06   826 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.1626821871198934e-06   827 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.159812616910437e-06   828 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.1569466070762114e-06   829 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.154084150444375e-06   830 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.1512252398620765e-06   831 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.148369868196384e-06   832 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.145518028334223e-06   833 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.142669713182292e-06   834 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.139824915667005e-06   835 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.136983628734415e-06   836 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.134145845350146e-06   837 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.131311558499322e-06   838 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.128480761186501e-06   839 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.125653446435605e-06   840 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.12282960728985e-06   841 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.1200092368116785e-06   842 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.117192328082694e-06   843 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.114378874203591e-06   844 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.111568868294088e-06   845 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.108762303492862e-06   846 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.1059591729574795e-06   847 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.103159469864333e-06   848 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.100363187408571e-06   849 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.097570318804036e-06   850 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.094780857283196e-06   851 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.091994796097082e-06   852 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.089212128515222e-06   853 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.0864328478255735e-06   854 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.083656947334463e-06   855 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.08088442036652e-06   856 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.0781152602646116e-06   857 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.075349460389785e-06   858 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.072587014121194e-06   859 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.069827914856046e-06   860 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.0670721560095335e-06   861 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.06431973101477e-06   862 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.061570633322737e-06   863 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.058824856402207e-06   864 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.056082393739698e-06   865 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.0533432388394e-06   866 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.05060738522312e-06   867 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.047874826430216e-06   868 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.045145556017542e-06   869 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.042419567559383e-06   870 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.0396968546474015e-06   871 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.036977410890564e-06   872 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.034261229915097e-06   873 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.031548305364416e-06   874 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.028838630899075e-06   875 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.026132200196699e-06   876 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.023429006951932e-06   877 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.020729044876375e-06   878 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.018032307698529e-06   879 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.015338789163737e-06   880 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.012648483034125e-06   881 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.009961383088547e-06   882 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.0072774831225265e-06   883 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.004596776948198e-06   884 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  6.00191925839425e-06   885 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.999244921305874e-06   886 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.996573759544701e-06   887 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.993905766988749e-06   888 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.991240937532366e-06   889 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.988579265086178e-06   890 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.985920743577027e-06   891 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.983265366947922e-06   892 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.980613129157979e-06   893 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.9779640241823706e-06   894 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.97531804601227e-06   895 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.972675188654796e-06   896 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.970035446132958e-06   897 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.9673988124856075e-06   898 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.964765281767374e-06   899 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.962134848048627e-06   900 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.959507505415407e-06   901 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.956883247969381e-06   902 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.954262069827792e-06   903 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.9516439651234e-06   904 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.9490289280044326e-06   905 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.946416952634534e-06   906 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.943808033192711e-06   907 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.941202163873287e-06   908 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.93859933888584e-06   909 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.935999552455159e-06   910 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.933402798821195e-06   911 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.930809072239004e-06   912 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.9282183669786985e-06   913 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.9256306773253986e-06   914 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.923045997579182e-06   915 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.92046432205503e-06   916 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.917885645082785e-06   917 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.915309961007093e-06   918 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.912737264187358e-06   919 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.910167548997696e-06   920 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.907600809826877e-06   921 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.905037041078287e-06   922 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.902476237169873e-06   923 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.899918392534095e-06   924 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.897363501617879e-06   925 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.894811558882568e-06   926 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.892262558803877e-06   927 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8897164958718425e-06   928 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.887173364590775e-06   929 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.884633159479212e-06   930 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.882095875069876e-06   931 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.879561505909619e-06   932 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.877030046559381e-06   933 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.874501491594145e-06   934 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.871975835602885e-06   935 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8694530731885265e-06   936 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.866933198967896e-06   937 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8644162075716746e-06   938 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8619020936443604e-06   939 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.859390851844212e-06   940 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.856882476843208e-06   941 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.854376963327009e-06   942 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8518743059949e-06   943 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.849374499559754e-06   944 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.846877538747988e-06   945 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8443834182995135e-06   946 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.841892132967697e-06   947 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.839403677519313e-06   948 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.836918046734503e-06   949 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.83443523540673e-06   950 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8319552383427365e-06   951 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.829478050362497e-06   952 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.827003666299182e-06   953 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.824532080999111e-06   954 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.822063289321707e-06   955 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.819597286139462e-06   956 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.817134066337886e-06   957 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8146736248154696e-06   958 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.8122159564836404e-06   959 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.809761056266722e-06   960 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.807308919101892e-06   961 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.80485953993914e-06   962 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.802412913741226e-06   963 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.7999690354836405e-06   964 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.797527900154563e-06   965 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.795089502754817e-06   966 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.792653838297838e-06   967 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.790220901809624e-06   968 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.787790688328701e-06   969 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.785363192906079e-06   970 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.782938410605214e-06   971 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.780516336501968e-06   972 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.7780969656845675e-06   973 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.775680293253566e-06   974 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.773266314321805e-06   975 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.770855024014369e-06   976 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.768446417468553e-06   977 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.766040489833822e-06   978 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.76363723627177e-06   979 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.761236651956082e-06   980 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.758838732072494e-06   981 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.756443471818761e-06   982 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.754050866404611e-06   983 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.751660911051708e-06   984 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.749273600993621e-06   985 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.746888931475775e-06   986 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.744506897755424e-06   987 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.742127495101608e-06   988 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.739750718795116e-06   989 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.737376564128447e-06   990 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.735005026405779e-06   991 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.732636100942924e-06   992 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.730269783067298e-06   993 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.727906068117882e-06   994 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.725544951445182e-06   995 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.723186428411197e-06   996 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.720830494389385e-06   997 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.7184771447646154e-06   998 Simulation failed at learning step:  173  reward  -300277.40751066606 loss  tensor(300000.7188, grad_fn=<SmoothL1LossBackward>)\n",
      "epsilon  5.716396447286787e-06   999 Simulation failed at learning step:  153  reward  -299994.02815960295 loss  tensor(300002.3750, grad_fn=<SmoothL1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "net=NN()\n",
    "'''\n",
    "for p in net.parameters():\n",
    "    torch.nn.init.uniform_(p, a=0, b=10)\n",
    "'''\n",
    "durations=[]\n",
    "rewards=[]\n",
    "losses=[]\n",
    "optimizer=torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "loss=torch.nn.SmoothL1Loss()\n",
    "t=0\n",
    "for episode in range(1000):\n",
    "    total_loss=0\n",
    "    cumulative_reward=0\n",
    "    initial_position=pk.vect(np.pi/6, 0, 50)\n",
    "    initial_velocity=pk.vect(0, 0, 0)\n",
    "    wind=pk.vect(5,0,0)\n",
    "    k=pk.kite(initial_position, initial_velocity)\n",
    "    initial_beta=k.beta(wind)\n",
    "    S_t=(14,3,initial_beta)\n",
    "    tensor_state=torch.tensor(S_t).float()\n",
    "    for i in range(horizon):\n",
    "        t+=1\n",
    "        eps=scheduling(eps0, t, 10000, exp=0.6)\n",
    "        #eps=eps0\n",
    "        q=net(tensor_state).reshape(3,3)\n",
    "        A_t=torch.randint(3,(2,)) if np.random.rand()<eps else (q==torch.max(q)).nonzero().reshape(-1)\n",
    "        A_t=A_t[0],A_t[1]\n",
    "        new_attack_angle, new_bank_angle=apply_action(S_t, A_t)\n",
    "        sim_status=k.evolve_system(new_attack_angle, new_bank_angle, integration_steps_per_learning_step, integration_step, wind)\n",
    "        if not sim_status==0:\n",
    "            R_t1 = scheduling(-300000.0, i, horizon/4)\n",
    "            #R_t1=-300000.0\n",
    "            cumulative_reward+=R_t1\n",
    "            rewards.append(cumulative_reward)\n",
    "            durations.append(i)\n",
    "            target=torch.tensor(R_t1)\n",
    "            l=loss(q[A_t], target)\n",
    "            print(\"epsilon \", eps, \" \", episode, \"Simulation failed at learning step: \", i, \" reward \", cumulative_reward, \"loss \", l.item())\n",
    "            optimizer.zero_grad()\n",
    "            losses.append(l)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            break\n",
    "        S_t1 = (new_attack_angle, new_bank_angle, k.beta(wind))\n",
    "        tensor_state=torch.tensor(S_t1).float()\n",
    "        R_t1 = k.reward(new_attack_angle, new_bank_angle, wind)\n",
    "        cumulative_reward+=R_t1\n",
    "        if i==int(horizon)-1:\n",
    "            print(episode, \"Simulation ended at learning step: \", i, \" reward \", cumulative_reward)\n",
    "            target=torch.tensor(R_t1)\n",
    "            rewards.append(cumulative_reward)\n",
    "            durations.append(i)\n",
    "        else:\n",
    "            target=R_t1+gamma*torch.max(net(tensor_state))\n",
    "        l=loss(q[A_t], target)\n",
    "        S_t=S_t1\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(l)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd4f12de220>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(durations, 'o')\n",
    "plt.plot(np.convolve(durations, np.ones(300), 'valid') / 300)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(rewards, 'o')\n",
    "plt.plot(np.convolve(rewards, np.ones(300), 'valid') / 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation failed at learning step:  30\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta=[]\n",
    "phi=[]\n",
    "r=[]\n",
    "net.eval()\n",
    "visits=np.zeros((n_attack, n_bank,n_beta))\n",
    "initial_position=pk.vect(np.pi/6, 0, 50)\n",
    "initial_velocity=pk.vect(0, 0, 0)\n",
    "wind=pk.vect(5,0,0)\n",
    "k=pk.kite(initial_position, initial_velocity)\n",
    "initial_beta=k.beta(wind)\n",
    "S_t=(14,3,initial_beta)\n",
    "for i in range(horizon):\n",
    "    tensor_state=torch.tensor(S_t).float()\n",
    "    q=net(tensor_state).reshape(3,3)\n",
    "    #print(q)\n",
    "    theta.append(k.position.theta)\n",
    "    phi.append(k.position.phi)\n",
    "    r.append(k.position.r)\n",
    "    A_t=(q==torch.max(q)).nonzero().reshape(-1)\n",
    "    A_t=A_t[0],A_t[1]\n",
    "    #print(A_t)\n",
    "    new_attack_angle, new_bank_angle=apply_action(S_t, A_t)\n",
    "    status=k.evolve_system(new_attack_angle, new_bank_angle, integration_steps_per_learning_step, integration_step, wind)\n",
    "    if not status==0:\n",
    "        print(\"Simulation failed at learning step: \", i)\n",
    "        break\n",
    "    S_t = (new_attack_angle, new_bank_angle, k.beta(wind))\n",
    "    visits[S_t]+=1\n",
    "    if i==int(horizon)-1:\n",
    "        print( \"Simulation ended at learning step: \", i)\n",
    "\n",
    "theta=np.array(theta)\n",
    "phi=np.array(phi)\n",
    "r=np.array(r)\n",
    "plot_trajectory(theta, phi, r)\n",
    "#print(visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.502833843231201\n",
      "3.502833843231201\n",
      "325 0 Simulation failed at learning step:  324  reward  -16524.609360644412\n",
      "167.77148388199038\n",
      "699 1 Simulation failed at learning step:  373  reward  -12230.893593338498\n",
      "488.432717436667\n",
      "886 2 Simulation failed at learning step:  186  reward  -299375.44479428924\n",
      "726.7410510008676\n",
      "954 3 Simulation failed at learning step:  67  reward  -298969.60726838\n",
      "726.7410510008676\n",
      "957 4 Simulation failed at learning step:  2  reward  -299942.97810092836\n",
      "726.7410510008676\n",
      "1397 5 Simulation failed at learning step:  439  reward  -9555.613881297786\n",
      "726.7410510008676\n",
      "1586 6 Simulation failed at learning step:  188  reward  -297039.7525094182\n",
      "726.7410510008676\n",
      "1946 7 Simulation failed at learning step:  359  reward  -15289.921865485298\n",
      "726.7410510008676\n",
      "2056 8 Simulation failed at learning step:  109  reward  -299781.84162247647\n",
      "726.7410510008676\n",
      "2358 9 Simulation failed at learning step:  301  reward  -19758.228363485832\n",
      "909.7365024344805\n",
      "2916 10 Simulation failed at learning step:  557  reward  -7170.4529272202635\n",
      "1021.2820089932775\n",
      "3325 11 Simulation failed at learning step:  408  reward  -12299.773876432124\n",
      "1021.2820089932775\n",
      "3522 12 Simulation failed at learning step:  196  reward  -298821.7812621763\n",
      "1021.2820089932775\n",
      "4264 13 Simulation failed at learning step:  741  reward  -4952.596429520387\n",
      "1162.010282765112\n",
      "4880 14 Simulation failed at learning step:  615  reward  -7804.989908653254\n",
      "1162.010282765112\n",
      "5433 15 Simulation failed at learning step:  552  reward  -6803.598127611671\n",
      "1312.922567934679\n",
      "5977 16 Simulation failed at learning step:  543  reward  -8886.866434296038\n",
      "1312.922567934679\n",
      "6692 17 Simulation failed at learning step:  714  reward  -6746.038546303602\n",
      "1312.922567934679\n",
      "18 Simulation ended at learning step:  899  reward  501.0214371064786\n",
      "1312.922567934679\n",
      "8038 19 Simulation failed at learning step:  445  reward  -11262.094016628438\n",
      "1312.922567934679\n",
      "8507 20 Simulation failed at learning step:  468  reward  -10555.166748256055\n",
      "1312.922567934679\n",
      "9202 21 Simulation failed at learning step:  694  reward  -7018.547047854181\n",
      "1312.922567934679\n",
      "9751 22 Simulation failed at learning step:  548  reward  -8819.37171519461\n",
      "1312.922567934679\n",
      "10216 23 Simulation failed at learning step:  464  reward  -9120.218421937534\n",
      "1428.373141688987\n",
      "10896 24 Simulation failed at learning step:  679  reward  -5294.482646361564\n",
      "712.5898386574868\n",
      "11346 25 Simulation failed at learning step:  449  reward  -11105.68705626352\n",
      "712.5898386574868\n",
      "11970 26 Simulation failed at learning step:  623  reward  -7762.274301106198\n",
      "712.5898386574868\n",
      "12550 27 Simulation failed at learning step:  579  reward  -8299.840901231357\n",
      "712.5898386574868\n",
      "13227 28 Simulation failed at learning step:  676  reward  -7126.737354134652\n",
      "712.5898386574868\n",
      "13979 29 Simulation failed at learning step:  751  reward  -4967.173304556799\n",
      "715.7215236961125\n",
      "14604 30 Simulation failed at learning step:  624  reward  -7752.802105231143\n",
      "715.7215236961125\n",
      "14856 31 Simulation failed at learning step:  251  reward  -40420.02574258738\n",
      "460.7804569962733\n",
      "15534 32 Simulation failed at learning step:  677  reward  -7155.4060652875605\n",
      "460.7804569962733\n",
      "15870 33 Simulation failed at learning step:  335  reward  -17102.41333423178\n",
      "429.64467694900685\n",
      "16435 34 Simulation failed at learning step:  564  reward  -8507.900437373311\n",
      "429.64467694900685\n",
      "16592 35 Simulation failed at learning step:  156  reward  -298743.2857665138\n",
      "431.2606591452253\n",
      "16817 36 Simulation failed at learning step:  224  reward  -299257.82095709135\n",
      "431.2606591452253\n",
      "17486 37 Simulation failed at learning step:  668  reward  -7269.991441788571\n",
      "431.2606591452253\n",
      "17809 38 Simulation failed at learning step:  322  reward  -18394.45989507896\n",
      "431.2606591452253\n",
      "18291 39 Simulation failed at learning step:  481  reward  -8799.463759052553\n",
      "431.2606591452253\n",
      "18915 40 Simulation failed at learning step:  623  reward  -7762.246196598447\n",
      "431.2606591452253\n",
      "19162 41 Simulation failed at learning step:  246  reward  -47089.94934500292\n",
      "431.2606591452253\n",
      "19817 42 Simulation failed at learning step:  654  reward  -6743.60473616332\n",
      "426.86637123188314\n",
      "20441 43 Simulation failed at learning step:  623  reward  -7765.429406137889\n",
      "426.86637123188314\n",
      "20875 44 Simulation failed at learning step:  433  reward  -9551.08501114009\n",
      "426.86637123188314\n",
      "21500 45 Simulation failed at learning step:  624  reward  -7753.030635975673\n",
      "426.86637123188314\n",
      "22305 46 Simulation failed at learning step:  804  reward  -6013.117591206248\n",
      "426.86637123188314\n",
      "22693 47 Simulation failed at learning step:  387  reward  -12912.713413601201\n",
      "408.2212299244416\n",
      "23251 48 Simulation failed at learning step:  557  reward  -8629.322810606805\n",
      "408.2212299244416\n",
      "23559 49 Simulation failed at learning step:  307  reward  -21484.77563549366\n",
      "354.21015201213\n",
      "23933 50 Simulation failed at learning step:  373  reward  -14355.641578099785\n",
      "354.21015201213\n",
      "24313 51 Simulation failed at learning step:  379  reward  -14152.10483556941\n",
      "354.21015201213\n",
      "24937 52 Simulation failed at learning step:  623  reward  -7765.339553257172\n",
      "354.21015201213\n",
      "25631 53 Simulation failed at learning step:  693  reward  -7034.480946872249\n",
      "354.21015201213\n",
      "25996 54 Simulation failed at learning step:  364  reward  -15010.61223517293\n",
      "354.21015201213\n",
      "26662 55 Simulation failed at learning step:  665  reward  -6516.863000395213\n",
      "354.21015201213\n",
      "27263 56 Simulation failed at learning step:  600  reward  -8075.480931794989\n",
      "354.5663966661702\n",
      "27997 57 Simulation failed at learning step:  733  reward  -6667.345577511632\n",
      "354.5663966661702\n",
      "28366 58 Simulation failed at learning step:  368  reward  -14740.623158311377\n",
      "354.5663966661702\n",
      "59 Simulation ended at learning step:  899  reward  410.97004528455614\n",
      "354.5663966661702\n",
      "29662 60 Simulation failed at learning step:  395  reward  -12738.253437827048\n",
      "366.1614793277887\n",
      "29961 61 Simulation failed at learning step:  298  reward  -22257.115981329516\n",
      "376.9358056187618\n",
      "62 Simulation ended at learning step:  899  reward  435.7088444578683\n",
      "376.9358056187618\n",
      "30957 63 Simulation failed at learning step:  95  reward  -295777.19579825294\n",
      "376.9358056187618\n",
      "31113 64 Simulation failed at learning step:  155  reward  -299422.28799949033\n",
      "376.9358056187618\n",
      "31913 65 Simulation failed at learning step:  799  reward  -6121.252198699662\n",
      "376.9358056187618\n",
      "32625 66 Simulation failed at learning step:  711  reward  -6853.518325544568\n",
      "376.9358056187618\n",
      "33294 67 Simulation failed at learning step:  668  reward  -7269.992895790412\n",
      "376.9358056187618\n",
      "33988 68 Simulation failed at learning step:  693  reward  -7028.131756668137\n",
      "376.9358056187618\n",
      "34657 69 Simulation failed at learning step:  668  reward  -7269.03215003771\n",
      "376.9358056187618\n",
      "35130 70 Simulation failed at learning step:  472  reward  -9624.034879782916\n",
      "376.9358056187618\n",
      "71 Simulation ended at learning step:  899  reward  432.64392552747347\n",
      "376.9358056187618\n",
      "36421 72 Simulation failed at learning step:  390  reward  -14081.19691620595\n",
      "376.9358056187618\n",
      "73 Simulation ended at learning step:  899  reward  1307.3532946924493\n",
      "376.9358056187618\n",
      "38093 74 Simulation failed at learning step:  771  reward  -6341.5256183044\n",
      "376.9358056187618\n",
      "38786 75 Simulation failed at learning step:  692  reward  -7037.8075793972785\n",
      "376.9358056187618\n",
      "39142 76 Simulation failed at learning step:  355  reward  -15602.184738371845\n",
      "376.9358056187618\n",
      "39874 77 Simulation failed at learning step:  731  reward  -6574.541373600166\n",
      "376.9358056187618\n",
      "40656 78 Simulation failed at learning step:  781  reward  -5456.350007420537\n",
      "384.48360274664805\n",
      "41087 79 Simulation failed at learning step:  430  reward  -11790.078571069638\n",
      "384.48360274664805\n",
      "41726 80 Simulation failed at learning step:  638  reward  -7540.079836590758\n",
      "384.48360274664805\n",
      "41943 81 Simulation failed at learning step:  216  reward  -297029.1600158144\n",
      "384.48360274664805\n",
      "42411 82 Simulation failed at learning step:  467  reward  -8596.520671447095\n",
      "384.48360274664805\n",
      "43076 83 Simulation failed at learning step:  664  reward  -5837.379737828114\n",
      "384.48360274664805\n",
      "43673 84 Simulation failed at learning step:  596  reward  -8055.693874439164\n",
      "384.48360274664805\n",
      "44284 85 Simulation failed at learning step:  610  reward  -7866.913848160806\n",
      "384.48360274664805\n",
      "44904 86 Simulation failed at learning step:  619  reward  -7733.576477881562\n",
      "384.48360274664805\n",
      "45519 87 Simulation failed at learning step:  614  reward  -7019.240266716394\n",
      "362.8672503349602\n",
      "46198 88 Simulation failed at learning step:  678  reward  -7180.164531284014\n",
      "362.8672503349602\n",
      "46612 89 Simulation failed at learning step:  413  reward  -12384.490234821435\n",
      "362.8672503349602\n",
      "47330 90 Simulation failed at learning step:  717  reward  -6799.756493822091\n",
      "362.8672503349602\n",
      "47752 91 Simulation failed at learning step:  421  reward  -12128.11850790086\n",
      "362.8672503349602\n",
      "48278 92 Simulation failed at learning step:  525  reward  -8295.996482149227\n",
      "392.3302027820413\n",
      "48475 93 Simulation failed at learning step:  196  reward  -302180.4126276324\n",
      "384.34614105807566\n",
      "49247 94 Simulation failed at learning step:  771  reward  -6313.241486509381\n",
      "384.34614105807566\n",
      "49491 95 Simulation failed at learning step:  243  reward  -50869.573291116765\n",
      "384.34614105807566\n",
      "50264 96 Simulation failed at learning step:  772  reward  -6333.686349952843\n",
      "384.34614105807566\n",
      "51140 97 Simulation failed at learning step:  875  reward  -5133.322882085073\n",
      "337.98871346992627\n",
      "51516 98 Simulation failed at learning step:  375  reward  -13409.29755104785\n",
      "329.36038790671637\n",
      "99 Simulation ended at learning step:  899  reward  -83.30055532998095\n",
      "292.57260674208896\n",
      "53182 100 Simulation failed at learning step:  765  reward  -6392.859238222887\n",
      "292.57260674208896\n",
      "53412 101 Simulation failed at learning step:  229  reward  -129561.630353798\n",
      "286.1679614654996\n",
      "54116 102 Simulation failed at learning step:  703  reward  -6951.401541261446\n",
      "286.1679614654996\n",
      "54524 103 Simulation failed at learning step:  407  reward  -12686.434878087395\n",
      "286.88707057128073\n",
      "54770 104 Simulation failed at learning step:  245  reward  -49116.315413223005\n",
      "286.88707057128073\n",
      "105 Simulation ended at learning step:  899  reward  844.8274172869889\n",
      "288.5276357919907\n",
      "55889 106 Simulation failed at learning step:  218  reward  -297984.77685102547\n",
      "288.5276357919907\n",
      "56116 107 Simulation failed at learning step:  226  reward  -299140.7527918581\n",
      "285.3407539898305\n",
      "56476 108 Simulation failed at learning step:  359  reward  -15191.89767541788\n",
      "285.3407539898305\n",
      "56804 109 Simulation failed at learning step:  327  reward  -18148.089929087266\n",
      "285.3407539898305\n",
      "110 Simulation ended at learning step:  899  reward  492.05473189491573\n",
      "285.3407539898305\n",
      "58145 111 Simulation failed at learning step:  440  reward  -11440.509929750559\n",
      "285.3407539898305\n",
      "58430 112 Simulation failed at learning step:  284  reward  -25425.367637784235\n",
      "285.3407539898305\n",
      "58910 113 Simulation failed at learning step:  479  reward  -9866.932678126972\n",
      "285.3407539898305\n",
      "59419 114 Simulation failed at learning step:  508  reward  -9074.319661688638\n",
      "285.3407539898305\n",
      "59893 115 Simulation failed at learning step:  473  reward  -10022.002206353744\n",
      "285.3407539898305\n",
      "60094 116 Simulation failed at learning step:  200  reward  -299050.2058856164\n",
      "291.1215280864297\n",
      "60904 117 Simulation failed at learning step:  809  reward  -6009.215943212744\n",
      "313.83770107010434\n",
      "61453 118 Simulation failed at learning step:  548  reward  -8383.716037672766\n",
      "336.38738684155845\n",
      "61839 119 Simulation failed at learning step:  385  reward  -13289.67530161531\n",
      "357.0326245612417\n",
      "62214 120 Simulation failed at learning step:  374  reward  -13848.653108856563\n",
      "378.7947689645696\n",
      "62977 121 Simulation failed at learning step:  762  reward  -6411.338933537222\n",
      "401.68022049087153\n",
      "63198 122 Simulation failed at learning step:  220  reward  -299054.1851760269\n",
      "363.8837093855473\n",
      "64077 123 Simulation failed at learning step:  878  reward  -5177.65930009104\n",
      "325.04536102119596\n",
      "64932 124 Simulation failed at learning step:  854  reward  -4680.658526969424\n",
      "307.78278561370786\n",
      "125 Simulation ended at learning step:  899  reward  959.5727970225352\n",
      "296.05948361849426\n",
      "66569 126 Simulation failed at learning step:  736  reward  -5942.921382359519\n",
      "304.03113945334536\n",
      "127 Simulation ended at learning step:  899  reward  899.6082294190477\n",
      "310.7465450740376\n",
      "68016 128 Simulation failed at learning step:  546  reward  -8286.007818393005\n",
      "316.3224254635742\n",
      "68709 129 Simulation failed at learning step:  692  reward  -6484.839532494763\n",
      "320.84560653229636\n",
      "130 Simulation ended at learning step:  899  reward  922.1701353722484\n",
      "324.4187745053789\n",
      "69917 131 Simulation failed at learning step:  307  reward  -20319.219319433098\n",
      "327.180515526137\n",
      "70551 132 Simulation failed at learning step:  633  reward  -7219.922039499933\n",
      "329.23964321364565\n",
      "71098 133 Simulation failed at learning step:  546  reward  -8263.185484908492\n",
      "330.80982697890175\n",
      "71866 134 Simulation failed at learning step:  767  reward  -5947.216364291215\n",
      "346.8576484997876\n",
      "72253 135 Simulation failed at learning step:  386  reward  -13291.491723424062\n",
      "353.291156345545\n",
      "73028 136 Simulation failed at learning step:  774  reward  -5857.66912352981\n",
      "368.7439680688349\n",
      "73749 137 Simulation failed at learning step:  720  reward  -6276.4446127418805\n",
      "384.7640099085066\n",
      "74080 138 Simulation failed at learning step:  330  reward  -17630.853410533997\n",
      "400.2987979957909\n",
      "74315 139 Simulation failed at learning step:  234  reward  -79325.20725526423\n",
      "405.8673760769514\n",
      "140 Simulation ended at learning step:  899  reward  991.2680223818173\n",
      "421.4093521680419\n",
      "75797 141 Simulation failed at learning step:  581  reward  -7787.37257126248\n",
      "426.2185902048408\n",
      "75932 142 Simulation failed at learning step:  134  reward  -298938.585320075\n",
      "437.8494724914308\n",
      "76500 143 Simulation failed at learning step:  567  reward  -8089.810850134516\n",
      "451.85128451247857\n",
      "144 Simulation ended at learning step:  899  reward  977.9886989138279\n",
      "466.73553795310966\n",
      "145 Simulation ended at learning step:  899  reward  950.4068449424283\n",
      "482.6751779133817\n",
      "78893 146 Simulation failed at learning step:  592  reward  -7682.348255715418\n",
      "492.9201519497002\n",
      "79713 147 Simulation failed at learning step:  819  reward  -5561.695506366022\n",
      "508.9395503733902\n",
      "80305 148 Simulation failed at learning step:  591  reward  -7782.1116811389165\n",
      "522.146306267528\n",
      "80955 149 Simulation failed at learning step:  649  reward  -7048.3962994654585\n",
      "535.5035317071723\n",
      "81422 150 Simulation failed at learning step:  466  reward  -10179.365447333672\n",
      "551.3652512949056\n",
      "81984 151 Simulation failed at learning step:  561  reward  -8182.881426572495\n",
      "577.1701906122668\n",
      "82629 152 Simulation failed at learning step:  644  reward  -7075.562280814301\n",
      "617.5395080654063\n",
      "83054 153 Simulation failed at learning step:  424  reward  -11527.972701524055\n",
      "631.6536579016346\n",
      "154 Simulation ended at learning step:  899  reward  996.269095737227\n",
      "641.8795407098877\n",
      "84103 155 Simulation failed at learning step:  148  reward  -299016.58222334983\n",
      "656.4373910609008\n",
      "84714 156 Simulation failed at learning step:  610  reward  -7462.421774253484\n",
      "668.7613160308125\n",
      "84867 157 Simulation failed at learning step:  152  reward  -299118.24331383413\n",
      "684.9848767710603\n",
      "85348 158 Simulation failed at learning step:  480  reward  -9858.769754404884\n",
      "702.7812905600418\n",
      "86104 159 Simulation failed at learning step:  755  reward  -5942.042041731659\n",
      "725.9672281209741\n",
      "86599 160 Simulation failed at learning step:  494  reward  -9487.380650413681\n",
      "740.0948940390302\n",
      "87307 161 Simulation failed at learning step:  707  reward  -6416.7259744274925\n",
      "765.3335497119826\n",
      "162 Simulation ended at learning step:  899  reward  981.8384014815836\n",
      "777.2541526606852\n",
      "88865 163 Simulation failed at learning step:  657  reward  -7009.2341381960705\n",
      "824.3435071178432\n",
      "89624 164 Simulation failed at learning step:  758  reward  -6445.803790836657\n",
      "824.3435071178432\n",
      "165 Simulation ended at learning step:  899  reward  867.3558801914369\n",
      "829.6962826812116\n",
      "91173 166 Simulation failed at learning step:  648  reward  -6837.3750113639\n",
      "841.3913199198837\n",
      "91463 167 Simulation failed at learning step:  289  reward  -23808.98833145988\n",
      "855.8613173081618\n",
      "91990 168 Simulation failed at learning step:  526  reward  -8810.21995256144\n",
      "873.0499926006119\n",
      "169 Simulation ended at learning step:  899  reward  953.4514296966444\n",
      "884.050588851437\n",
      "93780 170 Simulation failed at learning step:  889  reward  -5397.105490934682\n",
      "795.3109222967175\n",
      "94124 171 Simulation failed at learning step:  343  reward  -15785.14471123162\n",
      "677.3699225806029\n",
      "94460 172 Simulation failed at learning step:  335  reward  -16262.055085376185\n",
      "677.3699225806029\n",
      "94644 173 Simulation failed at learning step:  183  reward  -298308.0266632083\n",
      "677.3699225806029\n",
      "95138 174 Simulation failed at learning step:  493  reward  -9215.435927888237\n",
      "674.2500518820815\n",
      "95334 175 Simulation failed at learning step:  195  reward  -298125.4519199053\n",
      "707.4290401971901\n",
      "95543 176 Simulation failed at learning step:  208  reward  -299469.78737925796\n",
      "707.4290401971901\n",
      "96019 177 Simulation failed at learning step:  475  reward  -9526.447459970163\n",
      "707.4290401971901\n",
      "96485 178 Simulation failed at learning step:  465  reward  -10602.158353823534\n",
      "711.5559197268415\n",
      "97039 179 Simulation failed at learning step:  553  reward  -8699.891020442603\n",
      "735.9872171908249\n",
      "97658 180 Simulation failed at learning step:  618  reward  -7773.418464183185\n",
      "758.9386484374918\n",
      "98115 181 Simulation failed at learning step:  456  reward  -10095.319904136913\n",
      "782.0693083943722\n",
      "98550 182 Simulation failed at learning step:  434  reward  -10712.13215572043\n",
      "804.8699869045679\n",
      "99313 183 Simulation failed at learning step:  762  reward  -6416.882071849628\n",
      "827.7044543527935\n",
      "99753 184 Simulation failed at learning step:  439  reward  -10899.079037127542\n",
      "827.7044543527935\n",
      "100444 185 Simulation failed at learning step:  690  reward  -6861.747454193659\n",
      "827.7044543527935\n",
      "100917 186 Simulation failed at learning step:  472  reward  -10020.946886365029\n",
      "775.3014566824642\n",
      "101670 187 Simulation failed at learning step:  752  reward  -6491.002669865572\n",
      "737.63457095983\n",
      "102027 188 Simulation failed at learning step:  356  reward  -14237.707061090838\n",
      "707.4290401971901\n",
      "102280 189 Simulation failed at learning step:  252  reward  -39747.452725206815\n",
      "707.4290401971901\n",
      "102651 190 Simulation failed at learning step:  370  reward  -15102.546012272465\n",
      "707.4290401971901\n",
      "102837 191 Simulation failed at learning step:  185  reward  -299492.6066704404\n",
      "636.7779183092558\n",
      "103490 192 Simulation failed at learning step:  652  reward  -7856.7650611696845\n",
      "636.7779183092558\n",
      "103691 193 Simulation failed at learning step:  200  reward  -299342.4799226591\n",
      "630.8138015560614\n",
      "103915 194 Simulation failed at learning step:  223  reward  -299223.62624318746\n",
      "646.6001258058419\n",
      "104752 195 Simulation failed at learning step:  836  reward  -5681.591093684823\n",
      "662.515224651718\n",
      "105445 196 Simulation failed at learning step:  692  reward  -6918.784766289053\n",
      "676.0198646288595\n",
      "105943 197 Simulation failed at learning step:  497  reward  -9557.664275184048\n",
      "691.9515928193521\n",
      "106414 198 Simulation failed at learning step:  470  reward  -10540.899579157014\n",
      "707.7579447025564\n",
      "106649 199 Simulation failed at learning step:  234  reward  -79754.64718910807\n",
      "720.6171302510592\n",
      "107408 200 Simulation failed at learning step:  758  reward  -6445.162753919915\n",
      "736.6656639423813\n",
      "201 Simulation ended at learning step:  899  reward  490.7566336227334\n",
      "736.6656639423813\n",
      "109069 202 Simulation failed at learning step:  760  reward  -6413.537926273091\n",
      "736.6656639423813\n",
      "109633 203 Simulation failed at learning step:  563  reward  -8549.610578131453\n",
      "736.6656639423813\n",
      "204 Simulation ended at learning step:  899  reward  494.6973490624089\n",
      "736.6656639423813\n",
      "110956 205 Simulation failed at learning step:  422  reward  -11794.88456952744\n",
      "736.6656639423813\n",
      "206 Simulation ended at learning step:  899  reward  496.24564943058795\n",
      "719.9555150958884\n",
      "112609 207 Simulation failed at learning step:  752  reward  -6485.646894989491\n",
      "703.5637151107659\n",
      "113453 208 Simulation failed at learning step:  843  reward  -5852.459738581617\n",
      "651.5544231618195\n",
      "114323 209 Simulation failed at learning step:  869  reward  -5678.526545005515\n",
      "646.2433337708036\n",
      "115149 210 Simulation failed at learning step:  825  reward  -5917.5608035696305\n",
      "648.458729491573\n",
      "115565 211 Simulation failed at learning step:  415  reward  -12328.912903089085\n",
      "650.0639564996313\n",
      "116365 212 Simulation failed at learning step:  799  reward  -6193.768470348005\n",
      "650.6801213598919\n",
      "116660 213 Simulation failed at learning step:  294  reward  -23108.33441487547\n",
      "650.6186886647921\n",
      "116887 214 Simulation failed at learning step:  226  reward  -299479.1720182341\n",
      "649.9545005556124\n",
      "117311 215 Simulation failed at learning step:  423  reward  -12003.994495675186\n",
      "648.7718768760091\n",
      "216 Simulation ended at learning step:  899  reward  464.49007840569834\n",
      "647.1640238506957\n",
      "118753 217 Simulation failed at learning step:  541  reward  -8998.404015837288\n",
      "645.335793204476\n",
      "119323 218 Simulation failed at learning step:  569  reward  -8467.075187049088\n",
      "643.3483912424975\n",
      "219 Simulation ended at learning step:  899  reward  461.85067821375674\n",
      "641.2601744189103\n",
      "120581 220 Simulation failed at learning step:  357  reward  -15224.325396070419\n",
      "638.8593112984829\n",
      "121339 221 Simulation failed at learning step:  757  reward  -6438.357256224302\n",
      "636.1465123784172\n",
      "222 Simulation ended at learning step:  899  reward  467.12290014416925\n",
      "633.1566927933309\n",
      "223 Simulation ended at learning step:  899  reward  466.3449330583343\n",
      "629.9505212357899\n",
      "224 Simulation ended at learning step:  899  reward  465.986763160947\n",
      "626.6067328681597\n",
      "124571 225 Simulation failed at learning step:  531  reward  -9172.11113301366\n",
      "623.2113888686749\n",
      "125048 226 Simulation failed at learning step:  476  reward  -10390.893713673542\n",
      "630.4261456658543\n",
      "227 Simulation ended at learning step:  899  reward  536.6256211406127\n",
      "655.3347391515417\n",
      "126191 228 Simulation failed at learning step:  242  reward  -54033.47272531339\n",
      "661.7859585294991\n",
      "126528 229 Simulation failed at learning step:  336  reward  -17134.384033182676\n",
      "684.5752239883161\n",
      "127252 230 Simulation failed at learning step:  723  reward  -6647.446483662693\n",
      "708.4058017653484\n",
      "127916 231 Simulation failed at learning step:  663  reward  -7208.086829010621\n",
      "726.9811752303787\n",
      "128414 232 Simulation failed at learning step:  497  reward  -9802.002471368174\n",
      "751.9612353762561\n",
      "128637 233 Simulation failed at learning step:  222  reward  -299455.1185910888\n",
      "769.0527599542918\n",
      "129040 234 Simulation failed at learning step:  402  reward  -12880.118642786705\n",
      "783.7380472263129\n",
      "129360 235 Simulation failed at learning step:  319  reward  -18789.061171471025\n",
      "806.590870327759\n",
      "129726 236 Simulation failed at learning step:  365  reward  -14905.458716005909\n",
      "825.6474482457793\n",
      "130539 237 Simulation failed at learning step:  812  reward  -6091.508080254681\n",
      "845.3964952544655\n",
      "131008 238 Simulation failed at learning step:  468  reward  -10554.59555431967\n",
      "845.3964952544655\n",
      "131761 239 Simulation failed at learning step:  752  reward  -6483.482427930001\n",
      "737.1676385148298\n",
      "132407 240 Simulation failed at learning step:  645  reward  -7414.84878932048\n",
      "737.1676385148298\n",
      "132733 241 Simulation failed at learning step:  325  reward  -17820.062907675838\n",
      "737.1676385148298\n",
      "133573 242 Simulation failed at learning step:  839  reward  -5550.757575589323\n",
      "715.5252192760958\n",
      "134030 243 Simulation failed at learning step:  456  reward  -9809.928860076536\n",
      "669.1764971005668\n",
      "134664 244 Simulation failed at learning step:  633  reward  -6637.4381579210085\n",
      "669.1764971005668\n",
      "134959 245 Simulation failed at learning step:  294  reward  -20657.529225668422\n",
      "669.1764971005668\n",
      "135130 246 Simulation failed at learning step:  170  reward  -298371.2845396979\n",
      "669.1764971005668\n",
      "135569 247 Simulation failed at learning step:  438  reward  -11454.566056246904\n",
      "665.6080994903564\n",
      "136104 248 Simulation failed at learning step:  534  reward  -9034.317867027468\n",
      "665.6080994903564\n",
      "136867 249 Simulation failed at learning step:  762  reward  -6417.130828038633\n",
      "677.9455621990049\n",
      "137640 250 Simulation failed at learning step:  772  reward  -6333.922391488799\n",
      "668.9485439229234\n",
      "138157 251 Simulation failed at learning step:  516  reward  -8514.905680988904\n",
      "668.9485439229234\n",
      "138837 252 Simulation failed at learning step:  679  reward  -7054.772452746647\n",
      "668.9485439229234\n",
      "139113 253 Simulation failed at learning step:  275  reward  -27941.62730358075\n",
      "668.9485439229234\n",
      "139560 254 Simulation failed at learning step:  446  reward  -11180.710239075775\n",
      "668.9485439229234\n",
      "140194 255 Simulation failed at learning step:  633  reward  -7588.206118655825\n",
      "668.9485439229234\n",
      "140451 256 Simulation failed at learning step:  256  reward  -37655.43600532419\n",
      "668.9485439229234\n",
      "140752 257 Simulation failed at learning step:  300  reward  -21042.96098816759\n",
      "668.9485439229234\n",
      "141524 258 Simulation failed at learning step:  771  reward  -6329.767631457581\n",
      "684.0647349040171\n",
      "142287 259 Simulation failed at learning step:  762  reward  -6411.692319791309\n",
      "708.1641908129948\n",
      "142539 260 Simulation failed at learning step:  251  reward  -41848.17110699209\n",
      "708.1641908129948\n",
      "142955 261 Simulation failed at learning step:  415  reward  -9880.94996080341\n",
      "708.1641908129948\n",
      "143289 262 Simulation failed at learning step:  333  reward  -17457.608391930666\n",
      "708.1641908129948\n",
      "143860 263 Simulation failed at learning step:  570  reward  -8402.509505000204\n",
      "697.1289632720138\n",
      "144626 264 Simulation failed at learning step:  765  reward  -6392.503785352332\n",
      "688.5448516626742\n",
      "145321 265 Simulation failed at learning step:  694  reward  -7012.834668512479\n",
      "688.5448516626742\n",
      "145945 266 Simulation failed at learning step:  623  reward  -7765.584356088489\n",
      "688.5448516626742\n",
      "146393 267 Simulation failed at learning step:  447  reward  -11193.13742718332\n",
      "688.5448516626742\n",
      "146804 268 Simulation failed at learning step:  410  reward  -12720.582646018689\n",
      "688.5448516626742\n",
      "147260 269 Simulation failed at learning step:  455  reward  -10947.726564483955\n",
      "670.2326684072721\n",
      "147917 270 Simulation failed at learning step:  656  reward  -7397.562762189796\n",
      "670.2326684072721\n",
      "148219 271 Simulation failed at learning step:  301  reward  -21776.7526384257\n",
      "670.2326684072721\n",
      "148607 272 Simulation failed at learning step:  387  reward  -13657.152197821175\n",
      "670.2326684072721\n",
      "149257 273 Simulation failed at learning step:  649  reward  -7448.857834011629\n",
      "670.2326684072721\n",
      "149449 274 Simulation failed at learning step:  191  reward  -299471.9441175597\n",
      "670.2326684072721\n",
      "149670 275 Simulation failed at learning step:  220  reward  -299284.7322510511\n",
      "670.2326684072721\n",
      "276 Simulation ended at learning step:  899  reward  897.9520986586948\n",
      "670.2326684072721\n",
      "277 Simulation ended at learning step:  899  reward  912.1332198025038\n",
      "670.2326684072721\n",
      "278 Simulation ended at learning step:  899  reward  569.5243754105959\n",
      "670.2326684072721\n",
      "152892 279 Simulation failed at learning step:  521  reward  -9256.744919036015\n",
      "670.2326684072721\n",
      "153752 280 Simulation failed at learning step:  859  reward  -5311.294307075812\n",
      "670.2326684072721\n",
      "154462 281 Simulation failed at learning step:  709  reward  -6809.749497365168\n",
      "637.2542098255909\n",
      "282 Simulation ended at learning step:  899  reward  570.9188183364357\n",
      "637.2542098255909\n",
      "283 Simulation ended at learning step:  899  reward  566.9328642166366\n",
      "637.2542098255909\n",
      "284 Simulation ended at learning step:  899  reward  521.7322182058514\n",
      "618.5283980222217\n",
      "157739 285 Simulation failed at learning step:  576  reward  -8350.593664160255\n",
      "618.5283980222217\n",
      "286 Simulation ended at learning step:  899  reward  520.6790895366526\n",
      "618.5283980222217\n",
      "287 Simulation ended at learning step:  899  reward  557.4951186066502\n",
      "618.5283980222217\n",
      "159968 288 Simulation failed at learning step:  428  reward  -11956.856259365482\n",
      "618.5283980222217\n",
      "160342 289 Simulation failed at learning step:  373  reward  -14526.718703387905\n",
      "618.5283980222217\n",
      "161139 290 Simulation failed at learning step:  796  reward  -5776.614791796181\n",
      "618.5283980222217\n",
      "291 Simulation ended at learning step:  899  reward  568.81367637454\n",
      "618.5283980222217\n",
      "162373 292 Simulation failed at learning step:  333  reward  -17641.008589097335\n",
      "618.5283980222217\n",
      "162800 293 Simulation failed at learning step:  426  reward  -11712.312955477411\n",
      "618.5283980222217\n",
      "294 Simulation ended at learning step:  899  reward  569.320305312911\n",
      "618.5283980222217\n",
      "295 Simulation ended at learning step:  899  reward  814.7829945428214\n",
      "618.5283980222217\n",
      "296 Simulation ended at learning step:  899  reward  982.0084569470912\n",
      "618.5283980222217\n",
      "166170 297 Simulation failed at learning step:  669  reward  -6879.254125287384\n",
      "618.5283980222217\n",
      "298 Simulation ended at learning step:  899  reward  572.0174709398931\n",
      "618.5283980222217\n",
      "299 Simulation ended at learning step:  899  reward  575.6375796273687\n",
      "618.5283980222217\n",
      "168371 300 Simulation failed at learning step:  400  reward  -12671.255188007872\n",
      "618.5283980222217\n",
      "169102 301 Simulation failed at learning step:  730  reward  -6356.359955414338\n",
      "618.5283980222217\n",
      "170001 302 Simulation failed at learning step:  898  reward  -5529.384547019226\n",
      "618.5283980222217\n",
      "303 Simulation ended at learning step:  899  reward  966.6425408531426\n",
      "618.5283980222217\n",
      "304 Simulation ended at learning step:  899  reward  878.6446100014471\n",
      "618.5283980222217\n",
      "172164 305 Simulation failed at learning step:  362  reward  -14730.380058743913\n",
      "618.5283980222217\n",
      "172286 306 Simulation failed at learning step:  121  reward  -299184.05661270116\n",
      "630.2620559694925\n",
      "173137 307 Simulation failed at learning step:  850  reward  -5264.381139024999\n",
      "665.2847903300976\n",
      "173449 308 Simulation failed at learning step:  311  reward  -19939.97365228852\n",
      "682.2584228392524\n",
      "174123 309 Simulation failed at learning step:  673  reward  -7127.965456577978\n",
      "707.6450143061235\n",
      "174866 310 Simulation failed at learning step:  742  reward  -6579.674137663211\n",
      "738.7883538074242\n",
      "175136 311 Simulation failed at learning step:  269  reward  -30150.85983040095\n",
      "772.8584436968706\n",
      "175662 312 Simulation failed at learning step:  525  reward  -9221.016087129512\n",
      "803.8615039218636\n",
      "176444 313 Simulation failed at learning step:  781  reward  -5899.343299553571\n",
      "834.8788410900627\n",
      "176575 314 Simulation failed at learning step:  130  reward  -299386.12892977375\n",
      "867.0943219143408\n",
      "176976 315 Simulation failed at learning step:  400  reward  -12840.595290128496\n",
      "901.0434530860779\n",
      "177864 316 Simulation failed at learning step:  887  reward  -4698.873058147952\n",
      "935.2163959394462\n",
      "178058 317 Simulation failed at learning step:  193  reward  -299193.36123055767\n",
      "967.6920389117988\n",
      "178880 318 Simulation failed at learning step:  821  reward  -5051.966761734001\n",
      "1000.4888211296104\n",
      "179208 319 Simulation failed at learning step:  327  reward  -18025.34554551979\n",
      "1034.3395493143223\n",
      "179827 320 Simulation failed at learning step:  618  reward  -8322.975377161449\n",
      "1067.5322610581145\n",
      "180083 321 Simulation failed at learning step:  255  reward  -37608.22199905056\n",
      "1100.8049756623814\n",
      "322 Simulation ended at learning step:  899  reward  539.8497286909693\n",
      "1011.0832589237133\n",
      "181341 323 Simulation failed at learning step:  357  reward  -14889.566601584487\n",
      "1044.4620305308135\n",
      "324 Simulation ended at learning step:  899  reward  1110.975559772734\n",
      "1077.3884638793068\n",
      "183104 325 Simulation failed at learning step:  862  reward  -4758.381362519313\n",
      "1097.526368815819\n",
      "183481 326 Simulation failed at learning step:  376  reward  -14238.507393477255\n",
      "1132.5878602393352\n",
      "183949 327 Simulation failed at learning step:  467  reward  -10311.265998439407\n",
      "1162.7836677533992\n",
      "184701 328 Simulation failed at learning step:  751  reward  -6258.951300276461\n",
      "1191.0149146305155\n",
      "329 Simulation ended at learning step:  899  reward  560.5809543835454\n",
      "1138.5224535957086\n",
      "330 Simulation ended at learning step:  899  reward  525.4176183012087\n",
      "1128.4172936809616\n",
      "186983 331 Simulation failed at learning step:  481  reward  -10372.529621821059\n",
      "1148.5500527772465\n",
      "187521 332 Simulation failed at learning step:  537  reward  -8728.9354682523\n",
      "1177.418449837559\n",
      "188109 333 Simulation failed at learning step:  587  reward  -7871.4205919106835\n",
      "1191.4115186350818\n",
      "334 Simulation ended at learning step:  899  reward  594.2194436382705\n",
      "1218.842942080121\n",
      "189693 335 Simulation failed at learning step:  683  reward  -7256.402289515629\n",
      "1239.1849484703403\n",
      "189952 336 Simulation failed at learning step:  258  reward  -35808.843149068365\n",
      "1272.0091935294065\n",
      "190759 337 Simulation failed at learning step:  806  reward  -5607.465300324229\n",
      "1301.9266574899755\n",
      "191512 338 Simulation failed at learning step:  752  reward  -6104.29548993396\n",
      "1335.218312965539\n",
      "339 Simulation ended at learning step:  899  reward  543.0984303426342\n",
      "1273.0559378530595\n",
      "192723 340 Simulation failed at learning step:  310  reward  -20370.823373967294\n",
      "1269.0569673087557\n",
      "193256 341 Simulation failed at learning step:  532  reward  -9324.483527386044\n",
      "1298.2471097749703\n",
      "342 Simulation ended at learning step:  899  reward  549.146893911754\n",
      "1288.451562546557\n",
      "343 Simulation ended at learning step:  899  reward  566.3678722614445\n",
      "1249.7914302818492\n",
      "195956 344 Simulation failed at learning step:  899  reward  -5143.400283983371\n",
      "1224.3308549393948\n",
      "196645 345 Simulation failed at learning step:  688  reward  -6795.879845533766\n",
      "1214.7685331804855\n",
      "197008 346 Simulation failed at learning step:  362  reward  -15437.847876372602\n",
      "1214.7685331804855\n",
      "197844 347 Simulation failed at learning step:  835  reward  -5490.4418694513115\n",
      "1211.3663892095458\n",
      "198454 348 Simulation failed at learning step:  609  reward  -7833.750613469735\n",
      "1212.800463834384\n",
      "198614 349 Simulation failed at learning step:  159  reward  -299023.56857574603\n",
      "1241.7662529711865\n",
      "199088 350 Simulation failed at learning step:  473  reward  -10460.581987311743\n",
      "1272.057996307061\n",
      "199937 351 Simulation failed at learning step:  848  reward  -5772.542772308927\n",
      "1297.1753738579962\n",
      "352 Simulation ended at learning step:  899  reward  382.7580611036477\n",
      "1317.9265699948885\n",
      "353 Simulation ended at learning step:  899  reward  570.5521191601766\n",
      "1242.8786618125246\n",
      "354 Simulation ended at learning step:  899  reward  570.5521191601766\n",
      "1240.611202538607\n",
      "355 Simulation ended at learning step:  899  reward  570.5521191601766\n",
      "1229.5461069276225\n",
      "356 Simulation ended at learning step:  899  reward  570.5521191601766\n",
      "1225.2995858383333\n",
      "357 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1225.2995858383333\n",
      "358 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1225.2995858383333\n",
      "359 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1225.2995858383333\n",
      "360 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1225.2995858383333\n",
      "361 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1225.2995858383333\n",
      "362 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1225.2995858383333\n",
      "363 Simulation ended at learning step:  899  reward  568.8087337085926\n",
      "1225.2995858383333\n",
      "364 Simulation ended at learning step:  899  reward  420.74904748670707\n",
      "1201.2411695113467\n",
      "365 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1200.2912351291077\n",
      "366 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1200.2912351291077\n",
      "367 Simulation ended at learning step:  899  reward  568.4006168967163\n",
      "1200.2912351291077\n",
      "368 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1201.4030956291238\n",
      "369 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1204.8970854091626\n",
      "370 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1207.2955906877974\n",
      "371 Simulation ended at learning step:  899  reward  556.1436065413759\n",
      "1208.6228868361432\n",
      "372 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1208.9012913998424\n",
      "373 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1208.1529478341924\n",
      "374 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1206.4240537896246\n",
      "375 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1209.6807511661439\n",
      "376 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1215.2634206579528\n",
      "377 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1219.942978336224\n",
      "378 Simulation ended at learning step:  899  reward  415.993214971322\n",
      "1223.7393344141494\n",
      "379 Simulation ended at learning step:  899  reward  570.5523818944207\n",
      "1226.6812471764515\n",
      "380 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1228.8048817348867\n",
      "381 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1230.152095667089\n",
      "382 Simulation ended at learning step:  899  reward  570.5494541217826\n",
      "1230.7636023124405\n",
      "383 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1230.6797995924283\n",
      "384 Simulation ended at learning step:  899  reward  392.83516598541127\n",
      "1229.9412254612532\n",
      "385 Simulation ended at learning step:  899  reward  391.5183473933267\n",
      "1228.588830488156\n",
      "386 Simulation ended at learning step:  899  reward  555.011959086644\n",
      "1226.6637894026023\n",
      "387 Simulation ended at learning step:  899  reward  414.9004213108668\n",
      "1224.2070126810931\n",
      "388 Simulation ended at learning step:  899  reward  391.5183473933267\n",
      "1223.568562464121\n",
      "389 Simulation ended at learning step:  899  reward  391.67155977987085\n",
      "1226.641685617778\n",
      "235030 390 Simulation failed at learning step:  892  reward  -5669.051874400654\n",
      "1229.0635445256248\n",
      "391 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1230.8530755643878\n",
      "392 Simulation ended at learning step:  899  reward  570.5498629581359\n",
      "1232.0297971615182\n",
      "393 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1232.6133344957282\n",
      "394 Simulation ended at learning step:  899  reward  422.14796186199163\n",
      "1232.622979101324\n",
      "395 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1232.0780417780884\n",
      "396 Simulation ended at learning step:  899  reward  419.8558771542475\n",
      "1230.99816014402\n",
      "397 Simulation ended at learning step:  899  reward  417.8236187941692\n",
      "1229.4035648529186\n",
      "398 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1227.3152627089871\n",
      "399 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1224.7553398869816\n",
      "400 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1221.746919449324\n",
      "401 Simulation ended at learning step:  899  reward  570.5523818944207\n",
      "1218.3131989965623\n",
      "402 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1214.477483906756\n",
      "403 Simulation ended at learning step:  899  reward  570.5485374617923\n",
      "1210.2632248884513\n",
      "404 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1205.6940633221027\n",
      "405 Simulation ended at learning step:  899  reward  422.94597078709637\n",
      "1201.4039051416462\n",
      "406 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1200.8607715856035\n",
      "407 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1199.851226502994\n",
      "408 Simulation ended at learning step:  899  reward  554.9427950370263\n",
      "1198.3936204780266\n",
      "409 Simulation ended at learning step:  899  reward  415.5872564283877\n",
      "1196.5068814877213\n",
      "410 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1194.2104423540316\n",
      "411 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1191.5241510322012\n",
      "412 Simulation ended at learning step:  899  reward  570.5508862344711\n",
      "1188.4681582440617\n",
      "413 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1185.0627833405733\n",
      "414 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1181.3283786746008\n",
      "415 Simulation ended at learning step:  899  reward  495.54030309363117\n",
      "1177.285191727642\n",
      "416 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1172.9532384778447\n",
      "417 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1168.3521950581528\n",
      "418 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1163.501309276959\n",
      "419 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1158.4193302323895\n",
      "420 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1153.1244550006413\n",
      "421 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1147.634289559447\n",
      "422 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1141.9658296900461\n",
      "423 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1137.5054597902024\n",
      "424 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1134.460421580049\n",
      "425 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1138.5589780469763\n",
      "426 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1143.0821843949345\n",
      "427 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1147.176497886451\n",
      "428 Simulation ended at learning step:  899  reward  556.5535495439073\n",
      "1150.846314206916\n",
      "429 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1154.0968307616401\n",
      "430 Simulation ended at learning step:  899  reward  421.3426261934975\n",
      "1156.9340016842616\n",
      "431 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1159.364491987188\n",
      "432 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1161.3956313549195\n",
      "433 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1163.0353680287217\n",
      "434 Simulation ended at learning step:  899  reward  555.3701938613201\n",
      "1164.2922231629623\n",
      "435 Simulation ended at learning step:  899  reward  495.91543689592453\n",
      "1165.175245954881\n",
      "436 Simulation ended at learning step:  899  reward  420.2401726895669\n",
      "1165.6939697662579\n",
      "437 Simulation ended at learning step:  899  reward  569.5654828956857\n",
      "1165.8583693726641\n",
      "438 Simulation ended at learning step:  899  reward  421.0559519537042\n",
      "1165.6788194007786\n",
      "439 Simulation ended at learning step:  899  reward  495.91543689592453\n",
      "1165.1660538772603\n",
      "440 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1164.3311267349443\n",
      "441 Simulation ended at learning step:  899  reward  420.256676249349\n",
      "1163.1853730802632\n",
      "442 Simulation ended at learning step:  899  reward  495.91543689592453\n",
      "1161.7403710072865\n",
      "443 Simulation ended at learning step:  899  reward  565.600079897644\n",
      "1160.0079037567502\n",
      "444 Simulation ended at learning step:  899  reward  420.6506229172593\n",
      "1157.999922058077\n",
      "445 Simulation ended at learning step:  899  reward  495.4129707913185\n",
      "1155.7285065395765\n",
      "446 Simulation ended at learning step:  899  reward  421.404530184055\n",
      "1153.205830151476\n",
      "447 Simulation ended at learning step:  899  reward  495.91543689592453\n",
      "1150.4441206008235\n",
      "448 Simulation ended at learning step:  899  reward  556.2146629575672\n",
      "1147.455622853962\n",
      "449 Simulation ended at learning step:  899  reward  495.91543689592453\n",
      "1144.2525618218829\n",
      "450 Simulation ended at learning step:  899  reward  421.8318621523462\n",
      "1140.847105388208\n",
      "451 Simulation ended at learning step:  899  reward  495.91543689592453\n",
      "1137.2513279775835\n",
      "452 Simulation ended at learning step:  899  reward  496.31350497486784\n",
      "1133.4771748965798\n",
      "453 Simulation ended at learning step:  899  reward  421.59859455141265\n",
      "1129.5364277010985\n",
      "454 Simulation ended at learning step:  899  reward  495.91543689592453\n",
      "1125.4406708597778\n",
      "455 Simulation ended at learning step:  899  reward  495.5779478691104\n",
      "1121.201259979214\n",
      "456 Simulation ended at learning step:  899  reward  420.6506229172593\n",
      "1116.8292918451693\n",
      "457 Simulation ended at learning step:  899  reward  554.6573931732958\n",
      "1112.3355765192273\n",
      "458 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1107.7306117131122\n",
      "459 Simulation ended at learning step:  899  reward  569.7864745084007\n",
      "1103.024559628468\n",
      "460 Simulation ended at learning step:  899  reward  420.71546718070744\n",
      "1098.227226411644\n",
      "298772 461 Simulation failed at learning step:  741  reward  -6621.747351038275\n",
      "1093.3480443374135\n",
      "462 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1088.3960567904564\n",
      "463 Simulation ended at learning step:  899  reward  554.8003224327223\n",
      "1083.3799060708088\n",
      "464 Simulation ended at learning step:  899  reward  415.5872564283877\n",
      "1078.3078240152352\n",
      "465 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1073.1876253917865\n",
      "466 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1068.0267039977525\n",
      "467 Simulation ended at learning step:  899  reward  570.5506236825191\n",
      "1062.8320313722886\n",
      "468 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1057.6101580220434\n",
      "469 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1052.3672169903843\n",
      "470 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1047.108929570508\n",
      "471 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1041.8406129641403\n",
      "472 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "1036.567189706682\n",
      "473 Simulation ended at learning step:  899  reward  570.5520233630808\n",
      "1031.293198695741\n",
      "474 Simulation ended at learning step:  899  reward  419.86194098263604\n",
      "1026.022807672908\n",
      "475 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1020.7598270184885\n",
      "476 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1015.5077247250273\n",
      "477 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1010.26964241673\n",
      "478 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "1005.0484122800526\n",
      "479 Simulation ended at learning step:  899  reward  554.8181640508532\n",
      "999.8465747665314\n",
      "480 Simulation ended at learning step:  899  reward  415.5872564283877\n",
      "994.6663969229011\n",
      "481 Simulation ended at learning step:  899  reward  570.5523818944207\n",
      "989.5098911962675\n",
      "482 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "984.3788345543215\n",
      "483 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "979.2747877080747\n",
      "484 Simulation ended at learning step:  899  reward  570.5510731804061\n",
      "974.1991142109739\n",
      "485 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "969.1529992113492\n",
      "486 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "964.1374676441061\n",
      "487 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "959.1534016581865\n",
      "488 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "954.2015570983391\n",
      "489 Simulation ended at learning step:  899  reward  570.5502612076458\n",
      "949.282578885319\n",
      "490 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "944.3970151706133\n",
      "491 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "939.5453301792794\n",
      "492 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "934.7279156958575\n",
      "493 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "929.945101190408\n",
      "494 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "925.1971626207229\n",
      "495 Simulation ended at learning step:  899  reward  422.14796186199163\n",
      "920.4843299812067\n",
      "496 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "915.8067936971975\n",
      "497 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "911.1647099844009\n",
      "498 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "906.558205306066\n",
      "499 Simulation ended at learning step:  899  reward  420.36559170907407\n",
      "901.987380064941\n",
      "500 Simulation ended at learning step:  899  reward  421.1668650755087\n",
      "897.4523116652242\n",
      "501 Simulation ended at learning step:  899  reward  556.1436065413759\n",
      "892.9530570730417\n",
      "502 Simulation ended at learning step:  899  reward  569.7971788684133\n",
      "888.4896549934017\n",
      "503 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "884.0621277679351\n",
      "504 Simulation ended at learning step:  899  reward  569.2050677718825\n",
      "879.6704830819014\n",
      "505 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "875.3147155463746\n",
      "506 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "870.9948081928767\n",
      "507 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "866.7107338860541\n",
      "508 Simulation ended at learning step:  899  reward  570.0168754562787\n",
      "862.4624565896526\n",
      "509 Simulation ended at learning step:  899  reward  556.1436065413759\n",
      "858.2499323917083\n",
      "510 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "854.0731101970197\n",
      "511 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "849.9319320186701\n",
      "512 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "845.8263328280559\n",
      "513 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "841.7562399560998\n",
      "514 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "837.7215720669305\n",
      "515 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "516 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "517 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "518 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "519 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "520 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "521 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "522 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "523 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "524 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "525 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "526 Simulation ended at learning step:  899  reward  570.0911683907979\n",
      "834.0056143809192\n",
      "527 Simulation ended at learning step:  899  reward  556.1436065413759\n",
      "834.0056143809192\n",
      "528 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "834.0056143809192\n",
      "529 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "834.0056143809192\n",
      "530 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "834.0056143809192\n",
      "531 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "834.0056143809192\n",
      "532 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "834.0056143809192\n",
      "533 Simulation ended at learning step:  899  reward  570.0168754562787\n",
      "834.0056143809192\n",
      "534 Simulation ended at learning step:  899  reward  570.0168754562787\n",
      "834.0056143809192\n",
      "535 Simulation ended at learning step:  899  reward  570.0168754562787\n",
      "834.0056143809192\n",
      "536 Simulation ended at learning step:  899  reward  556.6784084833233\n",
      "834.0056143809192\n",
      "537 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "538 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "539 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "540 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "541 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "542 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "543 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "544 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "545 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "546 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "547 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "548 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "549 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "550 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "551 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "552 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "553 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "554 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "555 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "556 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "557 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "558 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "559 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "560 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "561 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "562 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "563 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "564 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "565 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "566 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "567 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "568 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "569 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "570 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "571 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "572 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "573 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "574 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "575 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "576 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "577 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "578 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "579 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "580 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "581 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "582 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "583 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "584 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "585 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "586 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "587 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "588 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "589 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "590 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "591 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "592 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "593 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "594 Simulation ended at learning step:  899  reward  570.123434809528\n",
      "834.0056143809192\n",
      "595 Simulation ended at learning step:  899  reward  419.86194098263604\n",
      "834.0056143809192\n",
      "596 Simulation ended at learning step:  899  reward  420.40744813148837\n",
      "834.0056143809192\n",
      "597 Simulation ended at learning step:  899  reward  555.589997091774\n",
      "834.0056143809192\n",
      "598 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "599 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "600 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "601 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "602 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "603 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "604 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "605 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "606 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "607 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "608 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "609 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "610 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "611 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "612 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "613 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "614 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "615 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "616 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "617 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "618 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "619 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "620 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "621 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "622 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "623 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "624 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "625 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "626 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "627 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "628 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "629 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "630 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "631 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "632 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "633 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "634 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "635 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "636 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "637 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "638 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "639 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "640 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "641 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "642 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "643 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "644 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "645 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "646 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "647 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "648 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "649 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "650 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "651 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "652 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "653 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "654 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "655 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "656 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "657 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "658 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "659 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "660 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "661 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "662 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "663 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "664 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "665 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "666 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "667 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "668 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "669 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "670 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "671 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "672 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "673 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "674 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "675 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "676 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "677 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "678 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "679 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "680 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "681 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "682 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "683 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "684 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "685 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "686 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "687 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "688 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "689 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "690 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "691 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "692 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "693 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "694 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "695 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "696 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "697 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "698 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "699 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "700 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "701 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "702 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "703 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "704 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "705 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "706 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "707 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "708 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "709 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "710 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "711 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "712 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "713 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "714 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "715 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "716 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "717 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "718 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "719 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "720 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "721 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "722 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "723 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "724 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "725 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "726 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "727 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "728 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "729 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "730 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "731 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "732 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "733 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "734 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "735 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "736 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "737 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "738 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "739 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "740 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "741 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "742 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "743 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "744 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "745 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "746 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "747 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "748 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "749 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "750 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "751 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "752 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "753 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "754 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "755 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "756 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "757 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "758 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "759 Simulation ended at learning step:  899  reward  556.5411891514095\n",
      "834.0056143809192\n",
      "760 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "761 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "762 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "763 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "764 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "765 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "766 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "767 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "768 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "769 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "770 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "771 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "772 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "773 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "774 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "775 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "776 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "777 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "778 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "779 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "780 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "781 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "782 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "783 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "784 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "785 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "786 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "787 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "788 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "789 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "790 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "791 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "792 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "793 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "794 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "795 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "796 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "797 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "798 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "799 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "800 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "801 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "802 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "803 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "804 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "805 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "806 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "807 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "808 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "809 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "810 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "811 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "812 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "813 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "814 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "815 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "816 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "817 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "818 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "819 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "820 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "821 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "822 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "823 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "824 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "825 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "826 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "827 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "828 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "829 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "830 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "831 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "832 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "833 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "834 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "835 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "836 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "837 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "838 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "839 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "840 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "841 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "842 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "843 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "844 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "845 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "846 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "847 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "848 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "849 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "850 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "851 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "852 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "853 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "854 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "855 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "856 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "857 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "858 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "859 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "860 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "861 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "862 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "863 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "864 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "865 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "866 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "867 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "868 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "869 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "870 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "871 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "872 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "873 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "874 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "875 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "876 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "877 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "878 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "879 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "880 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "881 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "882 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "883 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "884 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "885 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "886 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "887 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "888 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "889 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "890 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "891 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "892 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "893 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "894 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "895 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "896 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "897 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "898 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "899 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "900 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "901 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "902 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "903 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "904 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "905 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "906 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "907 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "908 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "909 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "910 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "911 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "912 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "913 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "914 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "915 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "916 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "917 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "918 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "919 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "920 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "921 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "922 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "923 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "924 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "925 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "926 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "927 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "928 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "929 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "930 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "931 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "932 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "933 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "934 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "935 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "936 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "937 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "938 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "939 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "940 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "941 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "942 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "943 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "944 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "945 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "946 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "947 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "948 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "949 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "950 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "951 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "952 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "953 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "954 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "955 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "956 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "957 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "958 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "959 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "960 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "961 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "962 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "963 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "964 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "965 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "966 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "967 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "968 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "969 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "970 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "971 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "972 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "973 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "974 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "975 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "976 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "977 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "978 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "979 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "980 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "981 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "982 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "983 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "984 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "985 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "986 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "987 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "988 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "989 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "990 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "991 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "992 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "993 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "994 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "995 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "996 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "997 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "998 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "999 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1000 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1001 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1002 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1003 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1004 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1005 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1006 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1007 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1008 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1009 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1010 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1011 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1012 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1013 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1014 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1015 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1016 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1017 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1018 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1019 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1020 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1021 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1022 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1023 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1024 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1025 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1026 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1027 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1028 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1029 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1030 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1031 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1032 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1033 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1034 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1035 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1036 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1037 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1038 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1039 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1040 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1041 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1042 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1043 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1044 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1045 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1046 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1047 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1048 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1049 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1050 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1051 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1052 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1053 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1054 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1055 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1056 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1057 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1058 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1059 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1060 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1061 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1062 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1063 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1064 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1065 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1066 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1067 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1068 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1069 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1070 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1071 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1072 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1073 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1074 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1075 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1076 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1077 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1078 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1079 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1080 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1081 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1082 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1083 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1084 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1085 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1086 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1087 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1088 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1089 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1090 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1091 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1092 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1093 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1094 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1095 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1096 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1097 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1098 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1099 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1100 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1101 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1102 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1103 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1104 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1105 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1106 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1107 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1108 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1109 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1110 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1111 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1112 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1113 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1114 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1115 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1116 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1117 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1118 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1119 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1120 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1121 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1122 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1123 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1124 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1125 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1126 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1127 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1128 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1129 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1130 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1131 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1132 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1133 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1134 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1135 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1136 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1137 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1138 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1139 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1140 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1141 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1142 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1143 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1144 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1145 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1146 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1147 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1148 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1149 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1150 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1151 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1152 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1153 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1154 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1155 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1156 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1157 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1158 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1159 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1160 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1161 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1162 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1163 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1164 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1165 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1166 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1167 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1168 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1169 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "834.0056143809192\n",
      "1170 Simulation ended at learning step:  899  reward  555.8397127988277\n",
      "833.9839098915776\n",
      "1171 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1172 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1173 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1174 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1175 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1176 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1177 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1178 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1179 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1180 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1181 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1182 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1183 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1184 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1185 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1186 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1187 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1188 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1189 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1190 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1191 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1192 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1193 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1194 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1195 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1196 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1197 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1198 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1199 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1200 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1201 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1202 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1203 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1204 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1205 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1206 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1207 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1208 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1209 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1210 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1211 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1212 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1213 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1214 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1215 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1216 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1217 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1218 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1219 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1220 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1221 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1222 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1223 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1224 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1225 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1226 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1227 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1228 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1229 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1230 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1231 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1232 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1233 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1234 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1235 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1236 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1237 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1238 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1239 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1240 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1241 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1242 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1243 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1244 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1245 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1246 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1247 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1248 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1249 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1250 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1251 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1252 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1253 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1254 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1255 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1256 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1257 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1258 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1259 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1260 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1261 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1262 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1263 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1264 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1265 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1266 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1267 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1268 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1269 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1270 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1271 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1272 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1273 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1274 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1275 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1276 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1277 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1278 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1279 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1280 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1281 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1282 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1283 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1284 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1285 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1286 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1287 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1288 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1289 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1290 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1291 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1292 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1293 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1294 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1295 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1296 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1297 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1298 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1299 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1300 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1301 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1302 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1303 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1304 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1305 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1306 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1307 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1308 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1309 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1310 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1311 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1312 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1313 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1314 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1315 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1316 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1317 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1318 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1319 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1320 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1321 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1322 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1323 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1324 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1325 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1326 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1327 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1328 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1329 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1330 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1331 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1332 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1333 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1334 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1335 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1336 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1337 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1338 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1339 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1340 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1341 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1342 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1343 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1344 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1345 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1346 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1347 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1348 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1349 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1350 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1351 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1352 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1353 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1354 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1355 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1356 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1357 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1358 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1359 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1360 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1361 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1362 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1363 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1364 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1365 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1366 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1367 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1368 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1369 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1370 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1371 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1372 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1373 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1374 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1375 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1376 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1377 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1378 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1379 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1380 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1381 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1382 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1383 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1384 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1385 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1386 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1387 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1388 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1389 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1390 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1391 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1392 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1393 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1394 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1395 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1396 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1397 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1398 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1399 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1400 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1401 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1402 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1403 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1404 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1405 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1406 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1407 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1408 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1409 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1410 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1411 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1412 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1413 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1414 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1415 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1416 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1417 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1418 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1419 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1420 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1421 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1422 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1423 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1424 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1425 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1426 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1427 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1428 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1429 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1430 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1431 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1432 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1433 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1434 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1435 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1436 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1437 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1438 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1439 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1440 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1441 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1442 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1443 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1444 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1445 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1446 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1447 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1448 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1449 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1450 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1451 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1452 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1453 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1454 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1455 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1456 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1457 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1458 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1459 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1460 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1461 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1462 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1463 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1464 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1465 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1466 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1467 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1468 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1469 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1470 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1471 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1472 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1473 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1474 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1475 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1476 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1477 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1478 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1479 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1480 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1481 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1482 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1483 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1484 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1485 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1486 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1487 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1488 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1489 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1490 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1491 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1492 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1493 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1494 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1495 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1496 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1497 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1498 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1499 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1500 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1501 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1502 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1503 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1504 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1505 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1506 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1507 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1508 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1509 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1510 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1511 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1512 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1513 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1514 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1515 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1516 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1517 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1518 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1519 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1520 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1521 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1522 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1523 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1524 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1525 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1526 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1527 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1528 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1529 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1530 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1531 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1532 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1533 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1534 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1535 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1536 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1537 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1538 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1539 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1540 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1541 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1542 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1543 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1544 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1545 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1546 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1547 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1548 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1549 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1550 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1551 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1552 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1553 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1554 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1555 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1556 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1557 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1558 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1559 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1560 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1561 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1562 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1563 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1564 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1565 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1566 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1567 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1568 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1569 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1570 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1571 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1572 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1573 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1574 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1575 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1576 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1577 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1578 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1579 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1580 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1581 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1582 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1583 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1584 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1585 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1586 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1587 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1588 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1589 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1590 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1591 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1592 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1593 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1594 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1595 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1596 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1597 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1598 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1599 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1600 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1601 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1602 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1603 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1604 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1605 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1606 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1607 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1608 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1609 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1610 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1611 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1612 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1613 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1614 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1615 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1616 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1617 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1618 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1619 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1620 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1621 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1622 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1623 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1624 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1625 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1626 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1627 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1628 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1629 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1630 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1631 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1632 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1633 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1634 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1635 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1636 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1637 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1638 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1639 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1640 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1641 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1642 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1643 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1644 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1645 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1646 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1647 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1648 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1649 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1650 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1651 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1652 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1653 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1654 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1655 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1656 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1657 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1658 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1659 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1660 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1661 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1662 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1663 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1664 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1665 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1666 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1667 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1668 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1669 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1670 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1671 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1672 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1673 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1674 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1675 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1676 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1677 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1678 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1679 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1680 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1681 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1682 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1683 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1684 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1685 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1686 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1687 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1688 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1689 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1690 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1691 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1692 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1693 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1694 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1695 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1696 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1697 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1698 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1699 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1700 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1701 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1702 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1703 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1704 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1705 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1706 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1707 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1708 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1709 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1710 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1711 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1712 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1713 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1714 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1715 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1716 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1717 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1718 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1719 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1720 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1721 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1722 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1723 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1724 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1725 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1726 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1727 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1728 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1729 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1730 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1731 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1732 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1733 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1734 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1735 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1736 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1737 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1738 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1739 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1740 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1741 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1742 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1743 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1744 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1745 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1746 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1747 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1748 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1749 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1750 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1751 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1752 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1753 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1754 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1755 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1756 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1757 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1758 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1759 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1760 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1761 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1762 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1763 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1764 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1765 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1766 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1767 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1768 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1769 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1770 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1771 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1772 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1773 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1774 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1775 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1776 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1777 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1778 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1779 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1780 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1781 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1782 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1783 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1784 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1785 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1786 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1787 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1788 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1789 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1790 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1791 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1792 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1793 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1794 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1795 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1796 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1797 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1798 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1799 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1800 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1801 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1802 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1803 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1804 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1805 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1806 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1807 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1808 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1809 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1810 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1811 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1812 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1813 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1814 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1815 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1816 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1817 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1818 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1819 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1820 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1821 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1822 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1823 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1824 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1825 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1826 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1827 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1828 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1829 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1830 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1831 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1832 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1833 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1834 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1835 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1836 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1837 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1838 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1839 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1840 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1841 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1842 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1843 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1844 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1845 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1846 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1847 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1848 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1849 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1850 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1851 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1852 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1853 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1854 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1855 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1856 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1857 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1858 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1859 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1860 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1861 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1862 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1863 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1864 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1865 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1866 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1867 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1868 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1869 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1870 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1871 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1872 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1873 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1874 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1875 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1876 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1877 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1878 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1879 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1880 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1881 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1882 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1883 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1884 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1885 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1886 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1887 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1888 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1889 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1890 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1891 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1892 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1893 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1894 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1895 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1896 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1897 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1898 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1899 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1900 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1901 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1902 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1903 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1904 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1905 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1906 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1907 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1908 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1909 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1910 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1911 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1912 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1913 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1914 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1915 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1916 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1917 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1918 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1919 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1920 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1921 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1922 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1923 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1924 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1925 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1926 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1927 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1928 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1929 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1930 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1931 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1932 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1933 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1934 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1935 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1936 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1937 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1938 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1939 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1940 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1941 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1942 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1943 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1944 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1945 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1946 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1947 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1948 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1949 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1950 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1951 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1952 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1953 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1954 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1955 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1956 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1957 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1958 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1959 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1960 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1961 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1962 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1963 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1964 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1965 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1966 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1967 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1968 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1969 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1970 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1971 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1972 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1973 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1974 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1975 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1976 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1977 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1978 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1979 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1980 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1981 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1982 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1983 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1984 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1985 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1986 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1987 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1988 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1989 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1990 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1991 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1992 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1993 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1994 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1995 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1996 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1997 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1998 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "1999 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2000 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2001 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2002 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2003 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2004 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2005 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2006 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2007 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2008 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2009 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2010 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2011 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2012 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2013 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2014 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2015 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2016 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2017 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2018 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2019 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2020 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2021 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2022 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2023 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2024 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2025 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2026 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2027 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2028 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2029 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2030 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2031 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2032 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2033 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2034 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2035 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2036 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2037 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2038 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2039 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2040 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2041 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2042 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2043 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2044 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2045 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2046 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2047 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2048 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2049 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2050 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2051 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2052 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2053 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2054 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2055 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2056 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2057 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2058 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2059 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2060 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2061 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2062 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2063 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2064 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2065 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2066 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2067 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2068 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2069 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2070 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2071 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2072 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2073 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2074 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2075 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2076 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2077 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2078 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2079 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2080 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2081 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2082 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2083 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2084 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2085 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2086 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2087 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2088 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2089 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2090 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2091 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2092 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2093 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2094 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2095 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2096 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2097 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2098 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2099 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2100 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2101 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2102 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2103 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2104 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2105 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2106 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2107 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2108 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2109 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2110 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2111 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2112 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2113 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2114 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2115 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2116 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2117 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2118 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2119 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2120 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2121 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2122 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2123 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2124 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2125 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2126 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2127 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2128 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2129 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2130 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2131 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2132 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2133 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2134 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2135 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2136 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2137 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2138 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2139 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2140 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2141 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2142 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2143 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2144 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2145 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2146 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2147 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2148 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2149 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2150 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2151 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2152 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2153 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2154 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2155 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2156 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2157 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2158 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2159 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2160 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2161 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2162 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2163 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2164 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2165 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2166 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2167 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2168 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2169 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2170 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2171 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2172 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2173 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2174 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2175 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2176 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2177 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2178 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2179 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2180 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2181 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2182 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2183 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2184 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2185 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2186 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2187 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2188 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2189 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2190 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2191 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2192 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2193 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2194 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2195 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2196 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2197 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2198 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2199 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2200 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2201 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2202 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2203 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2204 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2205 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2206 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2207 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2208 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2209 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2210 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2211 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2212 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2213 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2214 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2215 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2216 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2217 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2218 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2219 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2220 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2221 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2222 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2223 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2224 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2225 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2226 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2227 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2228 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2229 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2230 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2231 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2232 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2233 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2234 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2235 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2236 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2237 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2238 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2239 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2240 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2241 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2242 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2243 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2244 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2245 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2246 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2247 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2248 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2249 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2250 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2251 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2252 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2253 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2254 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2255 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2256 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2257 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2258 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2259 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2260 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2261 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2262 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2263 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2264 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2265 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2266 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2267 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2268 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2269 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2270 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2271 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2272 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2273 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2274 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2275 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2276 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2277 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2278 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2279 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2280 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2281 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2282 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2283 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2284 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2285 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2286 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2287 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2288 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2289 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2290 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2291 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2292 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2293 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2294 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2295 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2296 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2297 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2298 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2299 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2300 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2301 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2302 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2303 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2304 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2305 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2306 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2307 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2308 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2309 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2310 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2311 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2312 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2313 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2314 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2315 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2316 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2317 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2318 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2319 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2320 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2321 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2322 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2323 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2324 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2325 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2326 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2327 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2328 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2329 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2330 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2331 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2332 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2333 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2334 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2335 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2336 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2337 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2338 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2339 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2340 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2341 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2342 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2343 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2344 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2345 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2346 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2347 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2348 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2349 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2350 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2351 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2352 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2353 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2354 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2355 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2356 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2357 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2358 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2359 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2360 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2361 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2362 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2363 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2364 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2365 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2366 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2367 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2368 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2369 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2370 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2371 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2372 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2373 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2374 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2375 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2376 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2377 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2378 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2379 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2380 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2381 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2382 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2383 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2384 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2385 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2386 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2387 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2388 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2389 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2390 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2391 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2392 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2393 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2394 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2395 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2396 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2397 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2398 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2399 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2400 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2401 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2402 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2403 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2404 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2405 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2406 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2407 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2408 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2409 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2410 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2411 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2412 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2413 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2414 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2415 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2416 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2417 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2418 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2419 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2420 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2421 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2422 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2423 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2424 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2425 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2426 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2427 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2428 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2429 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2430 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2431 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2432 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2433 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2434 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2435 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2436 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2437 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2438 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2439 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2440 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2441 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2442 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2443 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2444 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2445 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2446 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2447 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2448 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2449 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2450 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2451 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2452 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2453 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2454 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2455 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2456 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2457 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2458 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2459 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2460 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2461 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2462 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2463 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2464 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2465 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2466 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2467 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2468 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2469 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2470 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2471 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2472 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2473 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2474 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2475 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2476 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2477 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2478 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2479 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2480 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2481 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2482 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2483 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2484 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2485 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2486 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2487 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2488 Simulation ended at learning step:  899  reward  556.6909192365887\n",
      "833.9839098915776\n",
      "2489 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2490 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2491 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2492 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2493 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2494 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2495 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2496 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2497 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2498 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2499 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2500 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2501 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2502 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2503 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2504 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2505 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2506 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2507 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2508 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2509 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2510 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2511 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2512 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2513 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2514 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2515 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2516 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2517 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2518 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2519 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2520 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2521 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2522 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2523 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2524 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2525 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2526 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2527 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2528 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2529 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2530 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2531 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2532 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2533 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2534 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2535 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2536 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2537 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2538 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2539 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2540 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2541 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2542 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2543 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2544 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2545 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2546 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2547 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2548 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2549 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2550 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2551 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2552 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2553 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2554 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2555 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2556 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2557 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2558 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2559 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2560 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2561 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2562 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2563 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2564 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2565 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2566 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2567 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2568 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2569 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2570 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2571 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2572 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2573 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2574 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2575 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2576 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2577 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2578 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2579 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2580 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2581 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2582 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2583 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2584 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2585 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2586 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2587 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2588 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2589 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2590 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2591 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2592 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2593 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2594 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2595 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2596 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2597 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2598 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2599 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2600 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2601 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2602 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2603 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2604 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2605 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2606 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2607 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2608 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2609 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2610 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2611 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2612 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2613 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2614 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2615 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2616 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2617 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2618 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2619 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2620 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2621 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2622 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2623 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2624 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2625 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2626 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2627 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2628 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2629 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2630 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2631 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2632 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2633 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2634 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2635 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2636 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2637 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2638 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2639 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2640 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2641 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2642 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2643 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2644 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2645 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2646 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2647 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2648 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2649 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2650 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2651 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2652 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2653 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2654 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2655 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2656 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2657 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2658 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2659 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2660 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2661 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2662 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2663 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2664 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2665 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2666 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2667 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2668 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2669 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2670 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2671 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2672 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2673 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2674 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2675 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2676 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2677 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2678 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2679 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2680 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2681 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2682 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2683 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2684 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2685 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2686 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2687 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2688 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2689 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2690 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2691 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2692 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2693 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2694 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2695 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2696 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2697 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2698 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2699 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2700 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2701 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2702 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2703 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2704 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2705 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2706 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2707 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2708 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2709 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2710 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2711 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2712 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2713 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2714 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2715 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2716 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2717 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2718 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2719 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2720 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2721 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2722 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2723 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2724 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2725 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2726 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2727 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2728 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2729 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2730 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2731 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2732 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2733 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2734 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2735 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2736 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2737 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2738 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2739 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2740 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2741 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2742 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2743 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2744 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2745 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2746 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2747 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2748 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2749 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2750 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2751 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2752 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2753 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2754 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2755 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2756 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2757 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2758 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2759 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2760 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2761 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2762 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2763 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2764 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2765 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2766 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2767 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2768 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2769 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2770 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2771 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2772 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2773 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2774 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2775 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2776 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2777 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2778 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2779 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2780 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2781 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2782 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2783 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2784 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2785 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2786 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2787 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2788 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2789 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2790 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2791 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2792 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2793 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2794 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2795 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2796 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2797 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2798 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2799 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2800 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2801 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2802 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2803 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2804 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2805 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2806 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2807 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2808 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2809 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2810 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2811 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2812 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2813 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2814 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2815 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2816 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2817 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2818 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2819 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2820 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2821 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2822 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2823 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2824 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2825 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2826 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2827 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2828 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2829 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2830 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2831 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2832 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2833 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2834 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2835 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2836 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2837 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2838 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2839 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2840 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2841 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2842 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2843 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2844 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2845 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2846 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2847 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2848 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2849 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2850 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2851 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2852 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2853 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2854 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2855 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2856 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2857 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2858 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2859 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2860 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2861 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2862 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2863 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2864 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2865 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2866 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2867 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2868 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2869 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2870 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2871 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2872 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2873 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2874 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2875 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2876 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2877 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2878 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2879 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2880 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2881 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2882 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2883 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2884 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2885 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2886 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2887 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2888 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2889 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2890 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2891 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2892 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2893 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2894 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2895 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2896 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2897 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2898 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2899 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2900 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2901 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2902 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2903 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2904 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2905 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2906 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2907 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2908 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2909 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2910 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2911 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2912 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2913 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2914 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2915 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2916 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2917 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2918 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2919 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2920 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2921 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2922 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2923 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2924 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2925 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2926 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2927 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2928 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2929 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2930 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2931 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2932 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2933 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2934 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2935 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2936 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2937 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2938 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2939 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2940 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2941 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2942 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2943 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2944 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2945 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2946 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2947 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2948 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2949 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2950 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2951 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2952 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2953 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2954 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2955 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2956 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2957 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2958 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2959 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2960 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2961 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2962 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2963 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2964 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2965 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2966 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2967 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2968 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2969 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2970 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2971 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2972 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2973 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2974 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2975 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2976 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2977 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2978 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2979 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2980 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2981 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2982 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2983 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2984 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2985 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2986 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2987 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2988 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2989 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2990 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2991 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2992 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2993 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2994 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2995 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2996 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2997 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2998 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "2999 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3000 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3001 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3002 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3003 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3004 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3005 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3006 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3007 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3008 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3009 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3010 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3011 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3012 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3013 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3014 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3015 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3016 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3017 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3018 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3019 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3020 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3021 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3022 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3023 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3024 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3025 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3026 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3027 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3028 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3029 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3030 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3031 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3032 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3033 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3034 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3035 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3036 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3037 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3038 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3039 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3040 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3041 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3042 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3043 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3044 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3045 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3046 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3047 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3048 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3049 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3050 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3051 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3052 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3053 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3054 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3055 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3056 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3057 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3058 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3059 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3060 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3061 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3062 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3063 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3064 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3065 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3066 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3067 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3068 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3069 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3070 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3071 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3072 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3073 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3074 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3075 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3076 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3077 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3078 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3079 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3080 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3081 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3082 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3083 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3084 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3085 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3086 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3087 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3088 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3089 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3090 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3091 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3092 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3093 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3094 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3095 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3096 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3097 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3098 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3099 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3100 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3101 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3102 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3103 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3104 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3105 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3106 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3107 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3108 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3109 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3110 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3111 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3112 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3113 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3114 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3115 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3116 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3117 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3118 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3119 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3120 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3121 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3122 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3123 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3124 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3125 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3126 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3127 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3128 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3129 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3130 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3131 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3132 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3133 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3134 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3135 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3136 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3137 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3138 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3139 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3140 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3141 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3142 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3143 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3144 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3145 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3146 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3147 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3148 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3149 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3150 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3151 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3152 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3153 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3154 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3155 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3156 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3157 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3158 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3159 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3160 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3161 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3162 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3163 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3164 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3165 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3166 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3167 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3168 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3169 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3170 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3171 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3172 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3173 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3174 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3175 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3176 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3177 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3178 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3179 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3180 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3181 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3182 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3183 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3184 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3185 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3186 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3187 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3188 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3189 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3190 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3191 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3192 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3193 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3194 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3195 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3196 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3197 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3198 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3199 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3200 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3201 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3202 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3203 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3204 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3205 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3206 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3207 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3208 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3209 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3210 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3211 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3212 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3213 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3214 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3215 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3216 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3217 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3218 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3219 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3220 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3221 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3222 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3223 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3224 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3225 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3226 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3227 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3228 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3229 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3230 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3231 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3232 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3233 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3234 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3235 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3236 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3237 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3238 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3239 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3240 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3241 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3242 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3243 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3244 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3245 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3246 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3247 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3248 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3249 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3250 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3251 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3252 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3253 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3254 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3255 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3256 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3257 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3258 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3259 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3260 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3261 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3262 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3263 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3264 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3265 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3266 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3267 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3268 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3269 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3270 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3271 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3272 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3273 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3274 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3275 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3276 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3277 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3278 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3279 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3280 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3281 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3282 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3283 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3284 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3285 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3286 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3287 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3288 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3289 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3290 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3291 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3292 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3293 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3294 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3295 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3296 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3297 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3298 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3299 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3300 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3301 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3302 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3303 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3304 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3305 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3306 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3307 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3308 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3309 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3310 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3311 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3312 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3313 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3314 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3315 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3316 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3317 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3318 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3319 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3320 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3321 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3322 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3323 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3324 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3325 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3326 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3327 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3328 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3329 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3330 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3331 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3332 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3333 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3334 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3335 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3336 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3337 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3338 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3339 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3340 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3341 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3342 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3343 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3344 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3345 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3346 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3347 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3348 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3349 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3350 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3351 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3352 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3353 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3354 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3355 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3356 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3357 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3358 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3359 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3360 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3361 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3362 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3363 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3364 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3365 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3366 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3367 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3368 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3369 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3370 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3371 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3372 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3373 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3374 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3375 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3376 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3377 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3378 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3379 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3380 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3381 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3382 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3383 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3384 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3385 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3386 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3387 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3388 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3389 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3390 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3391 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3392 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3393 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3394 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3395 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3396 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3397 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3398 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3399 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3400 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3401 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3402 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3403 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3404 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3405 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3406 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3407 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3408 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3409 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3410 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3411 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3412 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3413 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3414 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3415 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3416 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3417 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3418 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3419 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3420 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3421 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3422 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3423 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3424 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3425 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3426 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3427 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3428 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3429 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3430 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3431 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3432 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3433 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3434 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3435 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3436 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3437 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3438 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3439 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3440 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3441 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3442 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3443 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3444 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3445 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3446 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3447 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3448 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3449 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3450 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3451 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3452 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3453 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3454 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3455 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3456 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3457 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3458 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3459 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3460 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3461 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3462 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3463 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3464 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3465 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3466 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3467 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3468 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3469 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3470 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3471 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3472 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3473 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3474 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3475 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3476 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3477 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3478 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3479 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3480 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3481 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3482 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3483 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3484 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3485 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3486 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3487 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3488 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3489 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3490 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3491 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3492 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3493 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3494 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3495 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3496 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3497 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3498 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3499 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3500 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3501 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3502 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3503 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3504 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3505 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3506 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3507 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3508 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3509 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3510 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3511 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3512 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3513 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3514 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3515 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3516 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3517 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3518 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3519 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3520 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3521 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3522 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3523 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3524 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3525 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3526 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3527 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3528 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3529 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3530 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3531 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3532 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3533 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3534 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3535 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3536 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3537 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3538 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3539 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3540 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3541 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3542 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3543 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3544 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3545 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3546 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3547 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3548 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3549 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3550 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3551 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3552 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3553 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3554 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3555 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3556 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3557 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3558 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3559 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3560 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3561 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3562 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3563 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3564 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3565 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3566 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3567 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3568 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3569 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3570 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3571 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3572 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3573 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3574 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3575 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3576 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3577 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3578 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3579 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3580 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3581 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3582 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3583 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3584 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3585 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3586 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3587 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3588 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3589 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3590 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3591 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3592 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3593 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3594 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3595 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3596 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3597 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3598 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3599 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3600 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3601 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3602 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3603 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3604 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3605 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3606 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3607 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3608 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3609 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3610 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3611 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3612 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3613 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3614 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3615 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3616 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3617 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3618 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3619 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3620 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3621 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3622 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3623 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3624 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3625 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3626 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3627 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3628 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3629 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3630 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3631 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3632 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3633 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3634 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3635 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3636 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3637 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3638 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3639 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3640 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3641 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3642 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3643 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3644 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3645 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3646 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3647 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3648 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3649 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3650 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3651 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3652 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3653 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3654 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3655 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3656 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3657 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3658 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3659 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3660 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3661 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3662 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3663 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3664 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3665 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3666 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3667 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3668 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3669 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3670 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3671 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3672 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3673 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3674 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3675 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3676 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3677 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3678 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3679 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3680 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3681 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3682 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3683 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3684 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3685 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3686 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3687 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3688 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3689 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3690 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3691 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3692 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3693 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3694 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3695 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3696 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3697 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3698 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3699 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3700 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3701 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3702 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3703 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3704 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3705 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3706 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3707 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3708 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3709 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3710 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3711 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3712 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3713 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3714 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3715 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3716 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3717 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3718 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3719 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3720 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3721 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3722 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3723 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3724 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3725 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3726 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3727 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3728 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3729 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3730 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3731 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3732 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3733 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3734 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3735 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3736 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3737 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3738 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3739 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3740 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3741 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3742 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3743 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3744 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3745 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3746 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3747 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3748 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3749 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3750 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3751 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3752 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3753 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3754 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3755 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3756 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3757 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3758 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3759 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3760 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3761 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3762 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3763 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3764 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3765 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3766 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3767 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3768 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3769 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3770 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3771 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3772 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3773 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3774 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3775 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3776 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3777 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3778 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3779 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3780 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3781 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3782 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3783 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3784 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3785 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3786 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3787 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3788 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3789 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3790 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3791 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3792 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3793 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3794 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3795 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3796 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3797 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3798 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3799 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3800 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3801 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3802 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3803 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3804 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3805 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3806 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3807 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3808 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3809 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3810 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3811 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3812 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3813 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3814 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3815 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3816 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3817 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3818 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3819 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3820 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3821 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3822 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3823 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3824 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3825 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3826 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3827 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3828 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3829 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3830 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3831 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3832 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3833 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3834 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3835 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3836 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3837 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3838 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3839 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3840 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3841 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3842 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3843 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3844 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3845 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3846 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3847 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3848 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3849 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3850 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3851 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3852 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3853 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3854 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3855 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3856 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3857 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3858 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3859 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3860 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3861 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3862 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3863 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3864 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3865 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3866 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3867 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3868 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3869 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3870 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3871 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3872 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3873 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3874 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3875 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3876 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3877 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3878 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3879 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3880 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3881 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3882 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3883 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3884 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3885 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3886 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3887 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3888 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3889 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3890 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3891 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3892 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3893 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3894 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3895 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3896 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3897 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3898 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3899 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3900 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3901 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3902 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3903 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3904 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3905 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3906 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3907 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3908 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3909 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3910 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3911 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3912 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3913 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3914 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3915 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3916 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3917 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3918 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3919 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3920 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3921 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3922 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3923 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3924 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3925 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3926 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3927 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3928 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3929 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3930 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3931 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3932 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3933 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3934 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3935 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3936 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3937 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3938 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3939 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3940 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3941 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3942 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3943 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3944 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3945 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3946 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3947 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3948 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3949 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3950 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3951 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3952 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3953 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3954 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3955 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3956 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3957 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3958 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3959 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3960 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3961 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3962 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3963 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3964 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3965 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3966 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3967 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3968 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3969 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3970 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3971 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3972 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3973 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3974 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3975 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3976 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3977 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3978 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3979 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3980 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3981 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3982 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3983 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3984 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3985 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3986 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3987 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3988 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3989 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3990 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3991 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3992 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3993 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3994 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3995 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3996 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3997 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3998 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "3999 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4000 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4001 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4002 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4003 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4004 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4005 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4006 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4007 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4008 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4009 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4010 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4011 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4012 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4013 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4014 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4015 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4016 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4017 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4018 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4019 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4020 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4021 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4022 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4023 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4024 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4025 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4026 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4027 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4028 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4029 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4030 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4031 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4032 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4033 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4034 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4035 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4036 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4037 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4038 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4039 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4040 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4041 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4042 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4043 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4044 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4045 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4046 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4047 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4048 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4049 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4050 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4051 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4052 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4053 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4054 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4055 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4056 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4057 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4058 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4059 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4060 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4061 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4062 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4063 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4064 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4065 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4066 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4067 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4068 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4069 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4070 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4071 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4072 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4073 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4074 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4075 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4076 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4077 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4078 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4079 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4080 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4081 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4082 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4083 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4084 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4085 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4086 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4087 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4088 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4089 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4090 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4091 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4092 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4093 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4094 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4095 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4096 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4097 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4098 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4099 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4100 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4101 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4102 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4103 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4104 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4105 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4106 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4107 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4108 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4109 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4110 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4111 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4112 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4113 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4114 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4115 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4116 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4117 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4118 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4119 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4120 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4121 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4122 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4123 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4124 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4125 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4126 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4127 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4128 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4129 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4130 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4131 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4132 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4133 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4134 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4135 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4136 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4137 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4138 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4139 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4140 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4141 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4142 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4143 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4144 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4145 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4146 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4147 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4148 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4149 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4150 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4151 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4152 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4153 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4154 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4155 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4156 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4157 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4158 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4159 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4160 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4161 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4162 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4163 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4164 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4165 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4166 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4167 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4168 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4169 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4170 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4171 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4172 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4173 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4174 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4175 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4176 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4177 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4178 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4179 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4180 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4181 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4182 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4183 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4184 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4185 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4186 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4187 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4188 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4189 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4190 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4191 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4192 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4193 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4194 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4195 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4196 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4197 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4198 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4199 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4200 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4201 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4202 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4203 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4204 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4205 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4206 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4207 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4208 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4209 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4210 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4211 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4212 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4213 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4214 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4215 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4216 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4217 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4218 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4219 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4220 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4221 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4222 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4223 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4224 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4225 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4226 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4227 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4228 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4229 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4230 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4231 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4232 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4233 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4234 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4235 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4236 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4237 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4238 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4239 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4240 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4241 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4242 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4243 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4244 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4245 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4246 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4247 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4248 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4249 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4250 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4251 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4252 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4253 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4254 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4255 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4256 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4257 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4258 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4259 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4260 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4261 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4262 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4263 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4264 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4265 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4266 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4267 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4268 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4269 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4270 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4271 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4272 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4273 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4274 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4275 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4276 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4277 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4278 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4279 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4280 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4281 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4282 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4283 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4284 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4285 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4286 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4287 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4288 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4289 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4290 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4291 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4292 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4293 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4294 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4295 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4296 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4297 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4298 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4299 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4300 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4301 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4302 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4303 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4304 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4305 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4306 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4307 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4308 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4309 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4310 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4311 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4312 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4313 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4314 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4315 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4316 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4317 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4318 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4319 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4320 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4321 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4322 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4323 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4324 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4325 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4326 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4327 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4328 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4329 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4330 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4331 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4332 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4333 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4334 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4335 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4336 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4337 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4338 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4339 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4340 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4341 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4342 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4343 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4344 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4345 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4346 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4347 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4348 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4349 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4350 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4351 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4352 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4353 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4354 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4355 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4356 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4357 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4358 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4359 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4360 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4361 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4362 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4363 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4364 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4365 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4366 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4367 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4368 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4369 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4370 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4371 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4372 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4373 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4374 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4375 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4376 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4377 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4378 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4379 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4380 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4381 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4382 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4383 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4384 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4385 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4386 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4387 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4388 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4389 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4390 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4391 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4392 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4393 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4394 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4395 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4396 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4397 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4398 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4399 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4400 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4401 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4402 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4403 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4404 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4405 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4406 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4407 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4408 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4409 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4410 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4411 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4412 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4413 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4414 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4415 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4416 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4417 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4418 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4419 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4420 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4421 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4422 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4423 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4424 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4425 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4426 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4427 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4428 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4429 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4430 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4431 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4432 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4433 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4434 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4435 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4436 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4437 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4438 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4439 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4440 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4441 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4442 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4443 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4444 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4445 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4446 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4447 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4448 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4449 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4450 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4451 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4452 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4453 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4454 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4455 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4456 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4457 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4458 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4459 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4460 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4461 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4462 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4463 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4464 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4465 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4466 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4467 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4468 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4469 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4470 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4471 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4472 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4473 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4474 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4475 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4476 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4477 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4478 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4479 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4480 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4481 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4482 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4483 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4484 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4485 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4486 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4487 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4488 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4489 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4490 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4491 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4492 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4493 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4494 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4495 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4496 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4497 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4498 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4499 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4500 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4501 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4502 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4503 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4504 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4505 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4506 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4507 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4508 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4509 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4510 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4511 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4512 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4513 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4514 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4515 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4516 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4517 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4518 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4519 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4520 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4521 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4522 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4523 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4524 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4525 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4526 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4527 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4528 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4529 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4530 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4531 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4532 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4533 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4534 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4535 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4536 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4537 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4538 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4539 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4540 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4541 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4542 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4543 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4544 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4545 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4546 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4547 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4548 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4549 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4550 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4551 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4552 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4553 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4554 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4555 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4556 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4557 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4558 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4559 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4560 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4561 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4562 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4563 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4564 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4565 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4566 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4567 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4568 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4569 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4570 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4571 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4572 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4573 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4574 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4575 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4576 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4577 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4578 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4579 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4580 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4581 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4582 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4583 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4584 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4585 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4586 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4587 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4588 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4589 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4590 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4591 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4592 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4593 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4594 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4595 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4596 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4597 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4598 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4599 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4600 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4601 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4602 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4603 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4604 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4605 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4606 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4607 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4608 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4609 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4610 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4611 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4612 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4613 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4614 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4615 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4616 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4617 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4618 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4619 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4620 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4621 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4622 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4623 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4624 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4625 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4626 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4627 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4628 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4629 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4630 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4631 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4632 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4633 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4634 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4635 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4636 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4637 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4638 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4639 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4640 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4641 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4642 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4643 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4644 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4645 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4646 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4647 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4648 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4649 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4650 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4651 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4652 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4653 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4654 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4655 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4656 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4657 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4658 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4659 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4660 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4661 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4662 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4663 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4664 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4665 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4666 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4667 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4668 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4669 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4670 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4671 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4672 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4673 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4674 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4675 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4676 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4677 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4678 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4679 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4680 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4681 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4682 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4683 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4684 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4685 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4686 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4687 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4688 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4689 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4690 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4691 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4692 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4693 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4694 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4695 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4696 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4697 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4698 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4699 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4700 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4701 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4702 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4703 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4704 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4705 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4706 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4707 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4708 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4709 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4710 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4711 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4712 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4713 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4714 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4715 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4716 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4717 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4718 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4719 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4720 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4721 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4722 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4723 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4724 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4725 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4726 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4727 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4728 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4729 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4730 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4731 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4732 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4733 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4734 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4735 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4736 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4737 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4738 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4739 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4740 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4741 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4742 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4743 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4744 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4745 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4746 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4747 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4748 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4749 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4750 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4751 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4752 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4753 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4754 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4755 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4756 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4757 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4758 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4759 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4760 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4761 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4762 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4763 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4764 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4765 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4766 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4767 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4768 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4769 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4770 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4771 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4772 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4773 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4774 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4775 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4776 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4777 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4778 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4779 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4780 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4781 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4782 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4783 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4784 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4785 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4786 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4787 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4788 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4789 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4790 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4791 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4792 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4793 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4794 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4795 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4796 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4797 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4798 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4799 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4800 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4801 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4802 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4803 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4804 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4805 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4806 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4807 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4808 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4809 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4810 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4811 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4812 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4813 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4814 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4815 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4816 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4817 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4818 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4819 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4820 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4821 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4822 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4823 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4824 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4825 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4826 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4827 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4828 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4829 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4830 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4831 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4832 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4833 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4834 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4835 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4836 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4837 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4838 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4839 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4840 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4841 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4842 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4843 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4844 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4845 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4846 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4847 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4848 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4849 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4850 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4851 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4852 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4853 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4854 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4855 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4856 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4857 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4858 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4859 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4860 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4861 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4862 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4863 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4864 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4865 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4866 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4867 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4868 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4869 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4870 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4871 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4872 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4873 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4874 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4875 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4876 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4877 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4878 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4879 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4880 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4881 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4882 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4883 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4884 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4885 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4886 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4887 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4888 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4889 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4890 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4891 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4892 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4893 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4894 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4895 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4896 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4897 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4898 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4899 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4900 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4901 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4902 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4903 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4904 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4905 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4906 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4907 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4908 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4909 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4910 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4911 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4912 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4913 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4914 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4915 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4916 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4917 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4918 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4919 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4920 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4921 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4922 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4923 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4924 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4925 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4926 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4927 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4928 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4929 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4930 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4931 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4932 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4933 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4934 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4935 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4936 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4937 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4938 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4939 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4940 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4941 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4942 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4943 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4944 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4945 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4946 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4947 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4948 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4949 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4950 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4951 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4952 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4953 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4954 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4955 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4956 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4957 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4958 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4959 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4960 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4961 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4962 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4963 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4964 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4965 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4966 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4967 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4968 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4969 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4970 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4971 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4972 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4973 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4974 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4975 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4976 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4977 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4978 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4979 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4980 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4981 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4982 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4983 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4984 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4985 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4986 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4987 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4988 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4989 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4990 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4991 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4992 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4993 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4994 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4995 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4996 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4997 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4998 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "4999 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5000 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5001 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5002 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5003 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5004 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5005 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5006 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5007 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5008 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5009 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5010 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5011 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5012 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5013 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5014 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5015 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5016 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5017 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5018 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5019 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5020 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5021 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5022 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5023 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5024 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5025 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5026 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5027 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5028 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5029 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5030 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5031 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5032 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5033 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5034 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5035 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5036 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5037 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5038 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5039 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5040 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5041 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5042 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5043 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5044 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5045 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5046 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5047 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5048 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5049 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5050 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5051 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5052 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5053 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5054 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5055 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5056 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5057 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5058 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5059 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5060 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5061 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5062 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5063 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5064 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5065 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5066 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5067 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5068 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5069 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5070 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5071 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5072 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5073 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5074 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5075 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5076 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5077 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5078 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5079 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5080 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5081 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5082 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5083 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5084 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5085 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5086 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5087 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5088 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5089 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5090 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5091 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5092 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5093 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5094 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5095 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5096 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5097 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5098 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5099 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5100 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5101 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5102 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5103 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5104 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5105 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5106 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5107 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5108 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5109 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5110 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5111 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5112 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5113 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5114 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5115 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5116 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5117 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5118 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5119 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5120 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5121 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5122 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5123 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5124 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5125 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5126 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5127 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5128 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5129 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5130 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5131 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5132 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5133 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5134 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5135 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5136 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5137 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5138 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5139 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5140 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5141 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5142 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5143 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5144 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5145 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5146 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5147 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5148 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5149 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5150 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5151 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5152 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5153 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5154 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5155 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5156 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5157 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5158 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5159 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5160 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5161 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5162 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5163 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5164 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5165 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5166 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5167 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5168 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5169 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5170 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5171 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5172 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5173 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5174 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5175 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5176 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5177 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5178 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5179 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5180 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5181 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5182 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5183 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5184 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5185 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5186 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5187 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5188 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5189 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5190 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5191 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5192 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5193 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5194 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5195 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5196 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5197 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5198 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5199 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5200 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5201 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5202 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5203 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5204 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5205 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5206 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5207 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5208 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5209 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5210 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5211 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5212 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5213 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5214 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5215 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5216 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5217 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5218 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5219 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5220 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5221 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5222 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5223 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5224 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5225 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5226 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5227 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5228 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5229 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5230 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5231 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5232 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5233 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5234 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5235 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5236 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5237 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5238 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5239 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5240 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5241 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5242 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5243 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5244 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5245 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5246 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5247 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5248 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5249 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5250 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5251 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5252 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5253 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5254 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5255 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5256 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5257 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5258 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5259 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5260 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5261 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5262 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5263 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5264 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5265 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5266 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5267 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5268 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5269 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5270 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5271 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5272 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5273 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5274 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5275 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5276 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5277 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5278 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5279 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5280 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5281 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5282 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5283 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5284 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5285 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5286 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5287 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5288 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5289 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5290 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5291 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5292 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5293 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5294 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5295 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5296 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5297 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5298 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5299 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5300 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5301 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5302 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5303 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5304 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5305 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5306 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5307 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5308 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5309 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5310 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5311 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5312 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5313 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5314 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5315 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5316 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5317 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5318 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5319 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5320 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5321 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5322 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5323 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5324 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5325 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5326 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5327 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5328 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5329 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5330 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5331 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5332 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5333 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5334 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5335 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5336 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5337 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5338 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5339 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5340 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5341 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5342 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5343 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5344 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5345 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5346 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5347 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5348 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5349 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5350 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5351 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5352 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5353 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5354 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5355 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5356 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5357 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5358 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5359 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5360 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5361 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5362 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5363 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5364 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5365 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5366 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5367 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5368 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5369 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5370 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5371 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5372 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5373 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5374 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5375 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5376 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5377 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5378 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5379 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5380 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5381 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5382 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5383 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5384 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5385 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5386 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5387 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5388 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5389 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5390 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5391 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5392 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5393 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5394 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5395 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5396 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5397 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5398 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5399 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5400 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5401 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5402 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5403 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5404 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5405 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5406 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5407 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5408 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5409 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5410 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5411 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5412 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5413 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5414 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5415 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5416 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5417 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5418 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5419 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5420 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5421 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5422 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5423 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5424 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5425 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5426 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5427 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5428 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5429 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5430 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5431 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5432 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5433 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5434 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5435 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5436 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5437 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5438 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5439 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5440 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5441 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5442 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5443 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5444 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5445 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5446 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5447 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5448 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5449 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5450 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5451 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5452 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5453 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5454 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5455 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5456 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5457 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5458 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5459 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5460 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5461 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5462 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5463 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5464 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5465 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5466 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5467 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5468 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5469 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5470 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5471 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5472 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5473 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5474 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5475 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5476 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5477 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5478 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5479 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5480 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5481 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5482 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5483 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5484 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5485 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5486 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5487 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5488 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5489 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5490 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5491 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5492 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5493 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5494 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5495 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5496 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5497 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5498 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5499 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5500 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5501 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5502 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5503 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5504 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5505 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5506 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5507 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5508 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5509 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5510 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5511 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5512 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5513 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5514 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5515 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5516 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5517 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5518 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5519 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5520 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5521 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5522 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5523 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5524 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5525 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5526 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5527 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5528 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5529 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5530 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5531 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5532 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5533 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5534 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5535 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5536 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5537 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5538 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5539 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5540 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5541 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5542 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5543 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5544 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5545 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5546 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5547 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5548 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5549 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5550 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5551 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5552 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5553 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5554 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5555 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5556 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5557 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5558 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5559 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5560 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5561 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5562 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5563 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5564 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5565 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5566 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5567 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5568 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5569 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5570 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5571 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5572 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5573 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5574 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5575 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5576 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5577 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5578 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5579 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5580 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5581 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5582 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5583 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5584 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5585 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5586 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5587 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5588 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5589 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5590 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5591 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5592 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5593 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5594 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5595 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5596 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5597 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5598 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5599 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5600 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5601 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5602 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5603 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5604 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5605 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5606 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5607 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5608 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5609 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5610 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5611 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5612 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5613 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5614 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5615 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5616 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5617 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5618 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5619 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5620 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5621 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5622 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5623 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5624 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5625 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5626 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5627 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5628 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5629 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5630 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5631 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5632 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5633 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5634 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5635 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5636 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5637 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5638 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5639 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5640 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5641 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5642 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5643 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5644 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5645 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5646 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5647 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5648 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5649 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5650 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5651 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5652 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5653 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5654 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5655 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5656 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5657 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5658 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5659 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5660 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5661 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5662 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5663 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5664 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5665 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5666 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5667 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5668 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5669 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5670 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5671 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5672 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5673 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5674 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5675 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5676 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5677 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5678 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5679 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5680 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5681 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5682 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5683 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5684 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5685 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5686 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5687 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5688 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5689 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5690 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5691 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5692 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5693 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5694 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5695 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5696 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5697 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5698 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5699 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5700 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5701 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5702 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5703 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5704 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5705 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5706 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5707 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5708 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5709 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5710 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5711 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5712 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5713 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5714 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5715 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5716 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5717 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5718 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5719 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5720 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5721 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5722 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5723 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5724 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5725 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5726 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5727 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5728 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5729 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5730 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5731 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5732 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5733 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5734 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5735 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5736 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5737 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5738 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5739 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5740 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5741 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5742 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5743 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5744 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5745 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5746 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5747 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5748 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5749 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5750 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5751 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5752 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5753 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5754 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5755 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5756 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5757 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5758 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5759 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5760 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5761 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5762 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5763 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5764 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5765 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5766 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5767 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5768 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5769 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5770 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5771 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5772 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5773 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5774 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5775 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5776 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5777 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5778 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5779 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5780 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5781 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5782 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5783 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5784 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5785 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5786 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5787 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5788 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5789 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5790 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5791 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5792 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5793 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5794 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5795 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5796 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5797 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5798 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5799 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5800 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5801 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5802 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5803 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5804 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5805 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5806 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5807 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5808 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5809 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5810 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5811 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5812 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5813 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5814 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5815 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5816 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5817 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5818 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5819 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5820 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5821 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5822 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5823 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5824 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5825 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5826 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5827 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5828 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5829 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5830 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5831 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5832 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5833 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5834 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5835 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5836 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5837 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5838 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5839 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5840 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5841 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5842 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5843 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5844 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5845 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5846 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5847 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5848 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5849 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5850 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5851 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5852 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5853 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5854 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5855 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5856 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5857 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5858 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5859 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5860 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5861 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5862 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5863 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5864 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5865 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5866 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5867 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5868 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5869 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5870 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5871 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5872 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5873 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5874 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5875 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5876 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5877 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5878 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5879 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5880 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5881 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5882 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5883 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5884 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5885 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5886 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5887 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5888 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5889 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5890 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5891 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5892 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5893 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5894 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5895 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5896 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5897 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5898 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5899 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5900 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5901 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5902 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5903 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5904 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5905 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5906 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5907 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5908 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5909 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5910 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5911 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5912 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5913 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5914 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5915 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5916 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5917 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5918 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5919 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5920 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5921 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5922 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5923 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5924 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5925 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5926 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5927 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5928 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5929 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5930 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5931 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5932 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5933 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5934 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5935 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5936 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5937 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5938 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5939 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5940 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5941 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5942 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5943 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5944 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5945 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5946 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5947 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5948 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5949 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n",
      "5950 Simulation ended at learning step:  899  reward  556.6831125511603\n",
      "833.9839098915776\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bb9deeafda01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mA_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps_greedy_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnew_attack_angle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_bank_angle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msim_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevolve_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_attack_angle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_bank_angle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintegration_steps_per_learning_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintegration_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msim_status\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mR_t1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheduling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kitegen/pykite.py\u001b[0m in \u001b[0;36mevolve_system\u001b[0;34m(self, attack_angle, bank_angle, integration_steps, step, wind)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mC_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattack_angle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattack_angle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mpsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeg2rad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbank_angles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbank_angle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlibkite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintegration_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigitize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibkite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Q=np.ones((n_attack, n_bank, n_beta, 3, 3))\n",
    "for a in range(n_attack):\n",
    "    for b in range(n_bank):\n",
    "        Q[a,b,0]=net(torch.tensor([a,b,0]).float()).reshape(3,3).detach().numpy()\n",
    "print(np.max(Q))\n",
    "durations=[]\n",
    "rewards=[]\n",
    "eta0=.1\n",
    "episodes=6000\n",
    "t=0\n",
    "for j in range(episodes):\n",
    "    cumulative_reward=0\n",
    "    initial_position=pk.vect(np.pi/6, 0, 50)\n",
    "    initial_velocity=pk.vect(0, 0, 0)\n",
    "    wind=pk.vect(5,0,0)\n",
    "    k=pk.kite(initial_position, initial_velocity)\n",
    "    initial_beta=k.beta(wind)\n",
    "    S_t=(14,3,initial_beta)\n",
    "    print(np.max(Q))\n",
    "    for i in range(horizon):\n",
    "        t+=1\n",
    "        eps=scheduling(eps0, t, 200000)\n",
    "        eta=scheduling(eta0, t, 500000)\n",
    "        A_t=eps_greedy_policy(Q, S_t, eps)\n",
    "        new_attack_angle, new_bank_angle=apply_action(S_t, A_t)\n",
    "        sim_status=k.evolve_system(new_attack_angle, new_bank_angle, integration_steps_per_learning_step, integration_step, wind)\n",
    "        if not sim_status==0:\n",
    "            R_t1 = scheduling(-300000, i, horizon/4)\n",
    "            cumulative_reward+=R_t1\n",
    "            print(t, j, \"Simulation failed at learning step: \", i, \" reward \", cumulative_reward)\n",
    "            rewards.append(cumulative_reward)\n",
    "            durations.append(i)\n",
    "            Q=terminal_step(Q, S_t, A_t, R_t1, eta)\n",
    "            break\n",
    "        S_t1 = (new_attack_angle, new_bank_angle, k.beta(wind))\n",
    "        R_t1 = k.reward(new_attack_angle, new_bank_angle, wind)\n",
    "        cumulative_reward+=R_t1\n",
    "        A_t1=eps_greedy_policy(Q, S_t1, 0)\n",
    "        if i==int(horizon)-1:\n",
    "            Q=terminal_step(Q, S_t, A_t, R_t1, eta)\n",
    "            print(j, \"Simulation ended at learning step: \", i, \" reward \", cumulative_reward)\n",
    "            rewards.append(cumulative_reward)\n",
    "            durations.append(i)\n",
    "        else:\n",
    "            Q=step(Q, S_t, A_t, R_t1, S_t1, A_t1, eta, gamma)\n",
    "        S_t=S_t1\n",
    "        #A_t=A_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
